[
  {
    "objectID": "temp.html",
    "href": "temp.html",
    "title": "temp",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "temp.html#quarto",
    "href": "temp.html#quarto",
    "title": "temp",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "temp.html#running-code",
    "href": "temp.html#running-code",
    "title": "temp",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "start.html",
    "href": "start.html",
    "title": "Getting Started",
    "section": "",
    "text": "For this course we will be using R. R is a free software environment for statistical computing and graphics. To run the code blocks for this course on your own computer you will need to have installed R. This is available for Linux, MacOS and Windows.\n\nIMPORTANT: Mac users, make sure you have installed the right version of R for your laptop’s processor (M1/M2 or Intel)\nAt the time of publishing, I am using R version 4.3.1 (2023-06-16 ucrt)."
  },
  {
    "objectID": "start.html#quarto",
    "href": "start.html#quarto",
    "title": "temp",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "start.html#running-code",
    "href": "start.html#running-code",
    "title": "temp",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "start.html#install-r",
    "href": "start.html#install-r",
    "title": "Getting Started",
    "section": "",
    "text": "For this course we will be using R. R is a free software environment for statistical computing and graphics. To run the code blocks for this course on your own computer you will need to have installed R. This is available for Linux, MacOS and Windows.\n\nIMPORTANT: Mac users, make sure you have installed the right version of R for your laptop’s processor (M1/M2 or Intel)\nAt the time of publishing, I am using R version 4.3.1 (2023-06-16 ucrt)."
  },
  {
    "objectID": "start.html#install-r-studio",
    "href": "start.html#install-r-studio",
    "title": "Getting Started",
    "section": "Install R Studio",
    "text": "Install R Studio\nRStudio is an integrated development environment (IDE) that can make programming and other tasks easier in R. An open source edition is available to download and install.\n\nYou need to install R before you install R Studio."
  },
  {
    "objectID": "start.html#open-r-studio",
    "href": "start.html#open-r-studio",
    "title": "Getting Started",
    "section": "Open R Studio",
    "text": "Open R Studio\nOnce R and R Studio are installed, open R Studio on your computer and type the following in the Console to the left or bottom left of the screen, alongside the prompt, &gt;.\n\n\nCode\n1 + 1\n\n\nthen hit Enter/Return. You should, of course, obtain the answer 2, as below.\n\n\n[1] 2\n\n\nYou will also find that if you move your mouse to over the code block above, an option appears to copy the code to the clipboard, allowing you to then paste it into the R Console window in R Studio."
  },
  {
    "objectID": "start.html#install-additional-librariespackages",
    "href": "start.html#install-additional-librariespackages",
    "title": "Getting Started",
    "section": "Install additional libraries/packages",
    "text": "Install additional libraries/packages\nThe base functions of R are greatly extended by the very many packages/libraries that have been developed for it. At the time of writing, there are 19925 of these on CRAN, which is the main repository for them. Many of these have been grouped into ‘tasks’ and topic areas, which can be viewed here.\nMost of the packages that will be needed for this course will be installed as they are needed. However, some will be used so regularly that we should install them now. Cut and paste the following code chunk into the Console and hit Enter/Return.\n\n\nCode\ninstall.packages(\"proxy\", dependencies = TRUE)\ninstall.packages(\"sf\", dependencies = TRUE)\ninstall.packages(\"tidyverse\", dependencies = TRUE)\n\n\n\nRun the code above even if you have the packages installed already so that you also have available all the packages that these depend upon and link to."
  },
  {
    "objectID": "start.html#changing-the-working-directory",
    "href": "start.html#changing-the-working-directory",
    "title": "Getting Started",
    "section": "Changing the working directory",
    "text": "Changing the working directory\nIf you type getwd() into the R Console you will obtain your current working directory – the default location to look for files and to save content to. Mine is,\n\n\nCode\ngetwd()\n\n\n[1] \"C:/Users/profr/Dropbox/github/MandM\"\n\n\nYou may wish to change this to something else each time you start R. You can do this using the drop-down menus. There is also the function setwd(dir) – type ?setwd in the R Console to learn more."
  },
  {
    "objectID": "start.html#organising-your-files-in-a-project",
    "href": "start.html#organising-your-files-in-a-project",
    "title": "Getting Started",
    "section": "Organising your files in a project",
    "text": "Organising your files in a project\nRather than having to set your working directory each time you restart R, you could also create a new project in R by using File –&gt; New Project… from the dropdown menus and create it either in a new directory (probably most sensible) or an existing one.\nThere is nothing especially magical about a project in R. As stated here, “a project is simply a working directory designated with a .RProj file. When you open a project (using File/Open Project in RStudio or by double–clicking on the .Rproj file outside of R), the working directory will automatically be set to the directory that the .RProj file is located in.” However, it is that which makes it useful: when you open a project you know that you are going to be working in a specific folder on your computer which them becomes the default ‘container’ to save files to or to download them from.”\n\nIt would be a good idea to create a new project now which can then be the folder and working directory for this course and its contents."
  },
  {
    "objectID": "start.html#changing-the-appearance-of-r-studio",
    "href": "start.html#changing-the-appearance-of-r-studio",
    "title": "Getting Started",
    "section": "Changing the appearance of R Studio",
    "text": "Changing the appearance of R Studio\nYou may notice that I prefer a blue to a white screen when working in R. To change it to this, from the drop-down menus use Tools –&gt; Global Options… -&gt; Appearance, and select Solarized Dark as the Editor theme. You may, of course, have your own preference."
  },
  {
    "objectID": "index.html#about-the-course",
    "href": "index.html#about-the-course",
    "title": "Welcome",
    "section": "About the course",
    "text": "About the course\nThe contents of this course were first developed for a short course at the University of Cape Town (UCT) in August 2022. It also forms part of the MSc Geographic Data Science and Spatial Analytics in the School of Geographical Sciences, University of Bristol.\nThe aims of this course are to teach an introduction to mapping, spatial analysis in R. It is a course in geographic data science with a particular focus on mapping, measuring and modelling spatial patterns in data. The core parts of the course are:\n\nWhy use R for mapping and spatial modelling?\nThe basics of mapping in R\nThe Spatial Variable: from maps towards models\nSpatial clustering and spatial heterogeneity: measuring patterns in data\nHarnessing spatial autocorrelation with geographically weighted statistics\nSpatial regression models\n\n\nThis is a work in progress\nChanges will be made and additional content added over time so check back here for the latest updates."
  },
  {
    "objectID": "index.html#course-text",
    "href": "index.html#course-text",
    "title": "Welcome",
    "section": "Course text",
    "text": "Course text\nThe most relevant text for this course is Parts II (Chapters 7 to 9) and III (Chapters 10 to 17) of Spatial Data Science with Applications in R. An online version of the book is available here. It takes a deeper dive into the fundamentals of spatial data science than this course does and is more ‘technical’ but is a good resource to extend your knowledge of geographical/spatial data science."
  },
  {
    "objectID": "index.html#pre-reading",
    "href": "index.html#pre-reading",
    "title": "Welcome",
    "section": "Pre-reading",
    "text": "Pre-reading\nThe following short pre-reading is recommended for the course:\nHarris RJ (2019). Not just nuisance: spatialising social statistics. In A Whitworth (ed.) Towards a Spatial Social Policy: Bridging the Gap Between Geography and Social Policy. Chapter 8. Bristol: Policy Press. Available here (or, if that doesn’t work try here)."
  },
  {
    "objectID": "index.html#other-useful-resources",
    "href": "index.html#other-useful-resources",
    "title": "Welcome",
    "section": "Other useful resources",
    "text": "Other useful resources\nSpatial Regression Models for the Social Sciences covers similar statistical ground to this course, For University of Bristol students, it is available to view as an eBook here.\n\nIn addition, Geocomputation with R by Robin Lovelace, Jakub Nawosad & Jannes Muenchow offers an extremely useful reference to have to hand if you are stuck when undertaking geocomputation with R. There is a free online version available."
  },
  {
    "objectID": "index.html#provisional-masters-programme",
    "href": "index.html#provisional-masters-programme",
    "title": "Welcome",
    "section": "Provisional Masters programme",
    "text": "Provisional Masters programme\nFor the 2023-4 iteration of the Masters unit, the teaching schedule is:\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nLecture\nPractical\nContent\n\n\n\n\n1\n-\n-\n-\n-\n\n\n2\nMon Oct 2\n11am - noon\n2 - 4pm\nWhy R and set-up practical\n\n\n3\nMon Oct 9\n-\n1 - 3pm\nFlavours of R\n\n\n4\nMon Oct 16\n11am - noon\n1 - 3pm\nMapping the spatial variable 1\n\n\n5\nMon Oct 23\n-\n1 - 3pm\nMapping the spatial variable 2\n\n\n6\n-\n-\n-\n-\n\n\n7\n-\n-\n-\n-\n\n\n8\nMon Nov 13\n11am - noon\n1 - 3pm\nMeasuring spatial autocorrelation\n\n\n9\nMon Nov 20\n11am - noon\n1 - 3pm\nGeographically Weighted Statistics\n\n\n10\n-\n-\n-\n-\n\n\n11\nMon Dec 4\n11am - noon\n1 - 3pm\nSpatial regression + opportunity to work on assessment\n\n\n12\nMon Dec 11\n11am - noon\n1 - 3pm\nGeographically weighted regression + opportunity to work on assessment"
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Welcome",
    "section": "About the author",
    "text": "About the author\nThis course is authored by Richard Harris, Professor of Quantitative Social Geography at the University of Bristol. You can find out more about me, my research and other interests at https://profrichharris.github.io/. It is taught at the University with the assistance of Dr. Richard Timmerman.\n @profrichharris"
  },
  {
    "objectID": "index.html#copyright-notice",
    "href": "index.html#copyright-notice",
    "title": "Welcome",
    "section": "Copyright notice",
    "text": "Copyright notice\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n \n@GeogBristol #justsaying!"
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "A Cartographic Answer",
    "section": "",
    "text": "Let’s answer the ‘why?’ question with a quick example of R in use. We will not worry about the exact detail of what the code means at this stage or attempt to explain it in full. Instead, we will largely take it as we find it, copying and pasting from this webpage into the R Console. The focus is on some of what R can do from a geographic perspective and not, at this stage, on how it does it.\n\nIf you find that the + sign stays on your screen, in the R Console, for a while and isn’t followed by &gt; then you have either forgotten to hit Enter/Return or have not included all of the code that is needed to complete an operation (to complete a function, for example). You can always press esc on your keyboard and try again.\nIt was suggested in ‘Getting Started’ that you might want to create a new project for this course (a folder in which to save all the files). If you followed that advice, begin by using File –&gt; Open Project… from the dropdown menus. Or, if you didn’t, you could create a new project now (File –&gt; New Project…). Remember, all it really does is create a new folder in which to store all your files but that is useful because it will ensure your working directory is the same as that folder.\n\nMac users: to speed-up the rendering of the maps, it is recommended that you change the Backend Graphics Device to AGG. You can do this through the dropdown menus: Tools -&gt; Global Options…, then click on Graphics (next to Basic). This will matter more in later exercises but you might as well do it now.\n\n\nFirst, we will check that the necessary packages are installed and then require them, which means to load them so they are available to use. The usual way to install a package is with the function, install.packages() so, for example, the graphics package ggplot2 is installed using install.packages(\"ggplot2\"). The code below is a bit more elaborate as it checks which packages have not yet been installed and installs them. However, the two-step process is the same: install and then require,\n\nuse install.packages() to install packages – only needs to be done once on your computer, unless you re-install R / replace it with a more recent version;\nthen use require() to load the desired packages – needs to be done each time R is restarted.\n\n\n\nCode\n# Checks to see which packages are already installed:\ninstalled &lt;- installed.packages()[,1]\n# Creates a character vector of packages that are required:\npkgs &lt;- c(\"XML\", \"tidyverse\", \"readxl\", \"proxy\", \"sf\", \"ggplot2\",\n              \"classInt\", \"ggspatial\")\n# Checks which of the required packages have not yet been installed:\ninstall &lt;- pkgs[!(pkgs %in% installed)]\n# Installs any that have not yet been installed:\nif(length(install)) install.packages(install, dependencies = TRUE)\n# Silently loads (requires) all the packages that are needed:\ninvisible(lapply(pkgs, require, character.only = TRUE))\n\n\n\nThe use of # indicates a comment in the code. It is there just for explanation. It is not executable code (it is ignored not run).\n\n\n\nNext, we will download a data table published by Statistics South Africa that provides estimates of the number of people speaking various languages in the South African Provinces in 2011. These data were downloaded from https://superweb.statssa.gov.za/webapi/. The data are found in an Excel spreadsheet, which is read in and manipulated, converting the counts into percentages.\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/data/table_2022-06-22_17-36-26.xlsx?raw=true\", \"language.xlsx\", quiet = TRUE, mode = \"wb\")\n\nread_xlsx(\"language.xlsx\", sheet = \"Data Sheet 0\", skip = 8) |&gt;\n  rename(Name = 2) |&gt;\n  drop_na(Afrikaans) |&gt;\n  select(-1) |&gt;\n  mutate(across(where(is.numeric), ~ round(. / Total * 100, 2))) -&gt; languages\n\n\nHere is the top of the data, viewed in the R environment:\n\n\nCode\nhead(languages)\n\n\n# A tibble: 6 × 14\n  Name     Afrikaans English IsiNdebele IsiXhosa IsiZulu Sepedi Sesotho Setswana\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Eastern…      9.32    3.62       0.06    83.4     0.8    0.05    2.37     0.03\n2 Free St…     11.9     1.16       0.37     9.09    5.1    0.26   64.4      6.85\n3 Gauteng      14.4    12.5        1.94     7.59   21.5   10.7    13.1      8.39\n4 KwaZulu…      1.49   13.6        0.2      2.33   80.9    0.11    0.71     0.06\n5 Limpopo       2.32    0.55       1.49     0.27    0.65  52.2     1.32     1.58\n6 Mpumala…      6.15    1.66      12.1      1.49   26.4   10.8     3.66     2.72\n# ℹ 5 more variables: SiSwati &lt;dbl&gt;, Tshivenda &lt;dbl&gt;, Xitsonga &lt;dbl&gt;,\n#   Other &lt;dbl&gt;, Total &lt;dbl&gt;\n\n\nThere is often more than one way of achieving something in R. Here we could also use,\n\n\nCode\nslice_head(languages, n = 6)\n\n\n# A tibble: 6 × 14\n  Name     Afrikaans English IsiNdebele IsiXhosa IsiZulu Sepedi Sesotho Setswana\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Eastern…      9.32    3.62       0.06    83.4     0.8    0.05    2.37     0.03\n2 Free St…     11.9     1.16       0.37     9.09    5.1    0.26   64.4      6.85\n3 Gauteng      14.4    12.5        1.94     7.59   21.5   10.7    13.1      8.39\n4 KwaZulu…      1.49   13.6        0.2      2.33   80.9    0.11    0.71     0.06\n5 Limpopo       2.32    0.55       1.49     0.27    0.65  52.2     1.32     1.58\n6 Mpumala…      6.15    1.66      12.1      1.49   26.4   10.8     3.66     2.72\n# ℹ 5 more variables: SiSwati &lt;dbl&gt;, Tshivenda &lt;dbl&gt;, Xitsonga &lt;dbl&gt;,\n#   Other &lt;dbl&gt;, Total &lt;dbl&gt;\n\n\n\n\n\nWhat R allows is the opportunity to map the data without needing to go outside R to use separate software such as GIS. To do so, we will need a ‘blank map’ of the Provinces that can be joined with the data to create a choropleth map (a type of thematic map).\nFirst, we will download a pre-existing map, also from https://superweb.statssa.gov.za/webapi/.\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/boundary%20files/mapview.kmz?raw=true\", \"map.kmz\", quiet = TRUE, mode = \"wb\")\nunzip(\"map.kmz\")\nst_read(\"doc.kml\") |&gt;\n  select(-Description) -&gt; map\n\n\nHere is the outline of that map:\n\n\nCode\nggplot() +\n  geom_sf(data = map)\n\n\n\n\n\n\n\n\nNow we can link the data table to the map\n\n\nCode\nmap |&gt;\n  left_join(languages, by = \"Name\") -&gt; map\n\n\nand then plot one of the variables.\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"cartolight\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = IsiXhosa), alpha = 0.8) +\n  scale_fill_gradient(low = \"white\", high = \"dark blue\") +\n  ggtitle(\"% Population speaking Xhosa\")\n\n\n\n\n\n The really nice thing about this is that it is now very easy to change the appearance of the map with only minor updates to the code.\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"stamenwatercolor\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = English), alpha = 0.8) +\n  scale_fill_gradient(low = \"white\", high = \"dark red\") +\n  ggtitle(\"% Population speaking English\")\n\n\n\n\n\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"thunderforestlandscape\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = Afrikaans), alpha = 0.8, col = \"transparent\") +\n  scale_fill_gradient(low = \"white\", high = \"dark red\") +\n  annotation_north_arrow(which_north = \"grid\", location = \"topright\") +\n  ggtitle(\"% Population speaking Afrikaans\")\n\n\n\n\n\n\n\n\nFinally, once we are happy with it, we can export the image in a format suitable for a journal publication or to insert into other documents such as Microsoft Word.\nAs jpeg, to print quality:\n\n\nCode\nggsave(\"mymap.jpg\", device = \"jpeg\", width = 7, height = 6, units = \"in\",\n       dpi = \"print\")\n\n\nAs pdf:\n\n\nCode\nggsave(\"mymap.pdf\", device = \"pdf\", width = 7, height = 6, units = \"in\")\n\n\nAs bmp, to screen quality:\n\n\nCode\nggsave(\"mymap.bmp\", device = \"bmp\", width = 7, height = 6, units = \"in\",\n       dpi = \"screen\")\n\n\nIf we now look in your working directory, they should be there:\n\n\nCode\nlist.files(pattern = \"mymap\")\n\n\n[1] \"mymap.bmp\" \"mymap.jpg\" \"mymap.pdf\""
  },
  {
    "objectID": "why.html#a-worked-example",
    "href": "why.html#a-worked-example",
    "title": "A Cartographic Answer",
    "section": "",
    "text": "Let’s answer the ‘why?’ question with a quick example of R in use. We will not worry about the exact detail of what the code means at this stage or attempt to explain it in full. Instead, we will largely take it as we find it, copying and pasting from this webpage into the R Console. The focus is on some of what R can do from a geographic perspective and not, at this stage, on how it does it.\n\nIf you find that the + sign stays on your screen, in the R Console, for a while and isn’t followed by &gt; then you have either forgotten to hit Enter/Return or have not included all of the code that is needed to complete an operation (to complete a function, for example). You can always press esc on your keyboard and try again.\nIt was suggested in ‘Getting Started’ that you might want to create a new project for this course (a folder in which to save all the files). If you followed that advice, begin by using File –&gt; Open Project… from the dropdown menus. Or, if you didn’t, you could create a new project now (File –&gt; New Project…). Remember, all it really does is create a new folder in which to store all your files but that is useful because it will ensure your working directory is the same as that folder.\n\nMac users: to speed-up the rendering of the maps, it is recommended that you change the Backend Graphics Device to AGG. You can do this through the dropdown menus: Tools -&gt; Global Options…, then click on Graphics (next to Basic). This will matter more in later exercises but you might as well do it now.\n\n\nFirst, we will check that the necessary packages are installed and then require them, which means to load them so they are available to use. The usual way to install a package is with the function, install.packages() so, for example, the graphics package ggplot2 is installed using install.packages(\"ggplot2\"). The code below is a bit more elaborate as it checks which packages have not yet been installed and installs them. However, the two-step process is the same: install and then require,\n\nuse install.packages() to install packages – only needs to be done once on your computer, unless you re-install R / replace it with a more recent version;\nthen use require() to load the desired packages – needs to be done each time R is restarted.\n\n\n\nCode\n# Checks to see which packages are already installed:\ninstalled &lt;- installed.packages()[,1]\n# Creates a character vector of packages that are required:\npkgs &lt;- c(\"XML\", \"tidyverse\", \"readxl\", \"proxy\", \"sf\", \"ggplot2\",\n              \"classInt\", \"ggspatial\")\n# Checks which of the required packages have not yet been installed:\ninstall &lt;- pkgs[!(pkgs %in% installed)]\n# Installs any that have not yet been installed:\nif(length(install)) install.packages(install, dependencies = TRUE)\n# Silently loads (requires) all the packages that are needed:\ninvisible(lapply(pkgs, require, character.only = TRUE))\n\n\n\nThe use of # indicates a comment in the code. It is there just for explanation. It is not executable code (it is ignored not run).\n\n\n\nNext, we will download a data table published by Statistics South Africa that provides estimates of the number of people speaking various languages in the South African Provinces in 2011. These data were downloaded from https://superweb.statssa.gov.za/webapi/. The data are found in an Excel spreadsheet, which is read in and manipulated, converting the counts into percentages.\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/data/table_2022-06-22_17-36-26.xlsx?raw=true\", \"language.xlsx\", quiet = TRUE, mode = \"wb\")\n\nread_xlsx(\"language.xlsx\", sheet = \"Data Sheet 0\", skip = 8) |&gt;\n  rename(Name = 2) |&gt;\n  drop_na(Afrikaans) |&gt;\n  select(-1) |&gt;\n  mutate(across(where(is.numeric), ~ round(. / Total * 100, 2))) -&gt; languages\n\n\nHere is the top of the data, viewed in the R environment:\n\n\nCode\nhead(languages)\n\n\n# A tibble: 6 × 14\n  Name     Afrikaans English IsiNdebele IsiXhosa IsiZulu Sepedi Sesotho Setswana\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Eastern…      9.32    3.62       0.06    83.4     0.8    0.05    2.37     0.03\n2 Free St…     11.9     1.16       0.37     9.09    5.1    0.26   64.4      6.85\n3 Gauteng      14.4    12.5        1.94     7.59   21.5   10.7    13.1      8.39\n4 KwaZulu…      1.49   13.6        0.2      2.33   80.9    0.11    0.71     0.06\n5 Limpopo       2.32    0.55       1.49     0.27    0.65  52.2     1.32     1.58\n6 Mpumala…      6.15    1.66      12.1      1.49   26.4   10.8     3.66     2.72\n# ℹ 5 more variables: SiSwati &lt;dbl&gt;, Tshivenda &lt;dbl&gt;, Xitsonga &lt;dbl&gt;,\n#   Other &lt;dbl&gt;, Total &lt;dbl&gt;\n\n\nThere is often more than one way of achieving something in R. Here we could also use,\n\n\nCode\nslice_head(languages, n = 6)\n\n\n# A tibble: 6 × 14\n  Name     Afrikaans English IsiNdebele IsiXhosa IsiZulu Sepedi Sesotho Setswana\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Eastern…      9.32    3.62       0.06    83.4     0.8    0.05    2.37     0.03\n2 Free St…     11.9     1.16       0.37     9.09    5.1    0.26   64.4      6.85\n3 Gauteng      14.4    12.5        1.94     7.59   21.5   10.7    13.1      8.39\n4 KwaZulu…      1.49   13.6        0.2      2.33   80.9    0.11    0.71     0.06\n5 Limpopo       2.32    0.55       1.49     0.27    0.65  52.2     1.32     1.58\n6 Mpumala…      6.15    1.66      12.1      1.49   26.4   10.8     3.66     2.72\n# ℹ 5 more variables: SiSwati &lt;dbl&gt;, Tshivenda &lt;dbl&gt;, Xitsonga &lt;dbl&gt;,\n#   Other &lt;dbl&gt;, Total &lt;dbl&gt;\n\n\n\n\n\nWhat R allows is the opportunity to map the data without needing to go outside R to use separate software such as GIS. To do so, we will need a ‘blank map’ of the Provinces that can be joined with the data to create a choropleth map (a type of thematic map).\nFirst, we will download a pre-existing map, also from https://superweb.statssa.gov.za/webapi/.\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/boundary%20files/mapview.kmz?raw=true\", \"map.kmz\", quiet = TRUE, mode = \"wb\")\nunzip(\"map.kmz\")\nst_read(\"doc.kml\") |&gt;\n  select(-Description) -&gt; map\n\n\nHere is the outline of that map:\n\n\nCode\nggplot() +\n  geom_sf(data = map)\n\n\n\n\n\n\n\n\nNow we can link the data table to the map\n\n\nCode\nmap |&gt;\n  left_join(languages, by = \"Name\") -&gt; map\n\n\nand then plot one of the variables.\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"cartolight\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = IsiXhosa), alpha = 0.8) +\n  scale_fill_gradient(low = \"white\", high = \"dark blue\") +\n  ggtitle(\"% Population speaking Xhosa\")\n\n\n\n\n\n The really nice thing about this is that it is now very easy to change the appearance of the map with only minor updates to the code.\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"stamenwatercolor\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = English), alpha = 0.8) +\n  scale_fill_gradient(low = \"white\", high = \"dark red\") +\n  ggtitle(\"% Population speaking English\")\n\n\n\n\n\n\n\nCode\nggplot() +\n  annotation_map_tile(type = \"thunderforestlandscape\", progress = \"none\") +\n  geom_sf(data = map, aes(fill = Afrikaans), alpha = 0.8, col = \"transparent\") +\n  scale_fill_gradient(low = \"white\", high = \"dark red\") +\n  annotation_north_arrow(which_north = \"grid\", location = \"topright\") +\n  ggtitle(\"% Population speaking Afrikaans\")\n\n\n\n\n\n\n\n\nFinally, once we are happy with it, we can export the image in a format suitable for a journal publication or to insert into other documents such as Microsoft Word.\nAs jpeg, to print quality:\n\n\nCode\nggsave(\"mymap.jpg\", device = \"jpeg\", width = 7, height = 6, units = \"in\",\n       dpi = \"print\")\n\n\nAs pdf:\n\n\nCode\nggsave(\"mymap.pdf\", device = \"pdf\", width = 7, height = 6, units = \"in\")\n\n\nAs bmp, to screen quality:\n\n\nCode\nggsave(\"mymap.bmp\", device = \"bmp\", width = 7, height = 6, units = \"in\",\n       dpi = \"screen\")\n\n\nIf we now look in your working directory, they should be there:\n\n\nCode\nlist.files(pattern = \"mymap\")\n\n\n[1] \"mymap.bmp\" \"mymap.jpg\" \"mymap.pdf\""
  },
  {
    "objectID": "why.html#another-example",
    "href": "why.html#another-example",
    "title": "A Cartographic Answer",
    "section": "Another example",
    "text": "Another example\nThe following example is much more complex so please don’t be put off by it. I have included it to make a simple point – it does not take too many lines of code to produce a high quality visual output. It might take a little bit of searching around online to find the code and instruction to produce exactly what you want but I rarely struggle to find an answer fairly quickly.\nI originally developed the following maps in response to the release of the 2021 UK Census data showing the ethnic composition of small area neighbourhoods. The four cities – Birmingham, Leicester, London and Manchester – are the ones that are no longer majority White British (i.e. less than half their population self-identified as White British). A consequence of this demographic change is that the cities are becoming more ethnically diverse, which is what the maps show, using a standardised census geography that I also created in R.\n\n\nCode\n# Read-in the attribute data and the boundary file:\ndf &lt;- read_csv(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/data/diversity.csv?raw=true\")\nmap &lt;- st_read(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/boundary%20files/cities.geojson\", quiet = TRUE)\n\n# Although more complex, at heart what the following code does is\n# join the map to the data and then produce a separate map for\n# each city and time period, using a consistent style\ndf |&gt;\n  pivot_longer(where(is.numeric), values_to = \"index\", names_to = \"year\") %&gt;%\n  mutate(year = paste0(\"20\",substring(year, 3, 4))) %&gt;%\n  left_join(map, ., by = \"OAXXCD\") %&gt;%\n  mutate(group = paste(CITY, year, sep = \" ~ \")) %&gt;%\n  split(.$group) %&gt;%\n\n  lapply(function(x) {\n    \n    ggplot(data = x, aes(fill = index)) +\n      geom_sf(col = \"transparent\") +\n      scale_fill_viridis_c(\"Diversity\",\n                           values = c(0,0.25,0.5,0.7,0.85,0.95,1)) +\n      annotation_north_arrow(location = \"tl\",\n                            style = north_arrow_minimal(text_size = 10),\n                            height = unit(0.6, \"cm\"), width = unit(0.6, \"cm\")) +\n      annotation_scale(location = \"br\", style = \"ticks\", line_width = 0.5,\n                       text_cex = 0.5, tick_height = 0.4,\n                       height = unit(0.15, \"cm\"), text_pad = unit(0.10, \"cm\")) +\n      theme_minimal() +\n      theme(axis.text = element_blank(),\n            axis.ticks = element_blank(),\n            plot.title = element_text(size = 8, hjust = 0.5),\n            legend.title = element_text(size = 7, vjust = 3),\n            legend.text =element_text(size = 6), \n            panel.grid.major = element_blank(),\n            panel.grid.minor = element_blank(),\n            plot.margin = margin(t = 0,  \n                                 r = 0,  \n                                 b = 0,\n                                 l = 0)) +\n      labs(title = paste0(x$CITY[1], \": \", x$year[1]))\n  }) -&gt; g\n\n# The cowplot library offers some additional plotting functionality\nif(!(\"cowplot\" %in% installed)) install.packages(\"cowplot\")\nrequire(cowplot)\n\n# The following gets the common legend for the maps\n# and stops it being printed 12 times -- once will be enough!\nlegend &lt;- get_legend(g[[1]])\nlapply(g, function(x) {\n  x + theme(legend.position='none')\n}) -&gt; g\n\n# This brings all the maps together as one\nggdraw(plot_grid(plot_grid(plotlist = g, ncol=3, align='v'),\n                 plot_grid(NULL, legend, ncol=1, scale = 0.5),\n                 rel_widths=c(1, 0.1),\n                 rel_heights=c(1, 0,1))) -&gt; g\n\nprint(g)"
  },
  {
    "objectID": "why.html#convinced",
    "href": "why.html#convinced",
    "title": "A Cartographic Answer",
    "section": "Convinced?",
    "text": "Convinced?\nOf course, maps can also be produced in open source software such as QGIS and GIS software certainly have their use. R is not automatically better or necessarily a replacement for these. However, what it does offer is an integrated environment for what we might call geographic data science: we can download data from external websites, load and tidy-up those data, fit statistical or other models to them and map the results – all from within R. Our stages of working can be saved as scripts, which are faster to change and modify than using ‘point-and-click’ operations, and we can share our code with other people (even those using different operating systems) facilitating collaborative working and reproducible social-/ science. Finally, there are lots of packages available for reading, visualising, and analysing spatial data in R. Some of them are summarised here. These are attractive reasons for mapping and modelling within R."
  },
  {
    "objectID": "why.html#alternatives",
    "href": "why.html#alternatives",
    "title": "A Cartographic Answer",
    "section": "Alternatives",
    "text": "Alternatives\n\nAside from software such as QGIS, an interesting area of development is Geographic Data Science with Python. You can learn more about it here."
  },
  {
    "objectID": "why.html#need-more-convincing",
    "href": "why.html#need-more-convincing",
    "title": "A Cartographic Answer",
    "section": "Need more convincing?",
    "text": "Need more convincing?\nIf you have time, have a look at this exercise that we sometimes use with prospective students at University open days. The idea of the exercise is not to teach the students R but to show them how we use R for geographic data science in the School of Geographical Sciences. What the exercise does is take COVID-19 data for English neighbourhoods, fit statistical models to it and map the results – all in R. Again, it is the ability to use R for all the stages shown below that makes it so useful.\n\nSource: R for Data Science"
  },
  {
    "objectID": "base.html#introduction",
    "href": "base.html#introduction",
    "title": "Base R",
    "section": "Introduction",
    "text": "Introduction\nBase R is what you download from CRAN. You might think of it as classic R. A short introduction of ‘the basics’ is provided below. For a fuller introduction, see the software manual, An Introduction to R. It is worth reading even if you end-up regularly using the Tidyverse variant of R described in the next session as there are some tasks that are (in my opinion) easier to do using Base R or by mixing it up a little."
  },
  {
    "objectID": "base.html#functions",
    "href": "base.html#functions",
    "title": "Base R",
    "section": "Functions",
    "text": "Functions\nR is a functional programming language where functions ‘do things’ to objects. What they do is dependent upon the class/type and attributes of the objects that go into the function, and also on the arguments of the function.\nFor example, try typing the following into the R Console, which is the bottom left panel of R Studio. Type it alongside the prompt symbol, > then hit Enter/Return.\n\n\nCode\nround(10.32, digits = 0)\n\n\n[1] 10\n\n\nThis calls the function round(), which is operating on the numeric object, 10.32. The argument digits specifies the number of digits to round to. It is set to zero in the example above.\nBecause digits = 0 is the default value for the function, we could just write\n\n\nCode\nround(10.32)\n\n\n[1] 10\n\n\nand obtain the same answer as before. I know that digits = 0 is the default value because, as I type the name of the function into the R Console, I see the arguments of the function and any default values appear.\n\nWe can also find out more about the function, including some examples of its use, by opening its help file.\n\n\nCode\n?round\n\n\n Should we wish to round 10.32 to one digit then we are no longer rounding to the default of zero decimal places and must therefore specify the argument explicitly (the default is no longer what we want).\n\n\nCode\nround(10.32, digits = 1)\n\n\n[1] 10.3\n\n\nThe following also works because it preserves the order of the arguments in the function.\n\n\nCode\nround(10.32, 1)\n\n\n[1] 10.3\n\n\nIn other words, if we do not specifically state that x = 10.32 (where x is a numeric vector; here, 10.32) and digits = 1 then they will be taken as the first and second arguments of the function. This requires care to make sure they genuinely are in the right order. If you aren’t certain, then define the arguments explicitly because they will then work out of order.\n\n\nCode\nround(digits = 1, x = 10.32)\n\n\n[1] 10.3\n\n\n In the examples above, both the input to and output from the function are a numeric vector of type double. The input is:\n\n\nCode\nclass(10.32)\n\n\n[1] \"numeric\"\n\n\nCode\ntypeof(10.32)\n\n\n[1] \"double\"\n\n\nThe output is:\n\n\nCode\nclass(round(10.32, digits = 1))\n\n\n[1] \"numeric\"\n\n\nCode\ntypeof(round(10.32, digits = 1))\n\n\n[1] \"double\"\n\n\nNote how a function can be wrapped within a function, as in the example above: class(round(...)).\n At the moment we are using x = 10.32, which is a numeric vector of length 1,\n\n\nCode\nlength(10.32)\n\n\n[1] 1\n\n\nHowever, the round() function can operate on numeric vectors of other lengths too.\n\n\nCode\nround(c(1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7))\n\n\n[1] 1 2 3 4 6 7 8\n\n\nHere the combine function, c is used to create a vector of length 7, which is the input into round(). The output is of length 7 too.\n\n\nCode\nlength(round(c(1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7)))\n\n\n[1] 7\n\n\n\nThere are lots of functions for R and I often forget what I need. Fortunately, there is a large user community too and so a quick web search often helps me quickly find what I need. Don’t be afraid to do a Google search for what you need.\n\nWriting a new function\nWe can write our own functions. The following will take a number and report whether it is a prime number or not.\n\n\nCode\nis.prime <- function(x) {\n  if(x == 2) return(TRUE)\n  if(x < 2 | x %% floor(x) != 0) {\n    warning(\"Please enter an integer number above 1\")\n    return(NA)\n  }\n  y <- 2:(x-1)\n  ifelse(all(x%%y > 0), return(TRUE), return(FALSE))\n}\n\n\nLet’s try it.\n\n\nCode\nis.prime(2)\n\n\n[1] TRUE\n\n\nCode\nis.prime(10)\n\n\n[1] FALSE\n\n\nCode\nis.prime(13)\n\n\n[1] TRUE\n\n\nCode\nis.prime(3.3)\n\n\n[1] NA\n\n\n There is quite a lot to unpack about the function. It is not all immediately relevant but it is instructive to have an overview of what it is doing. First of all the function takes the form\nf <- function(x) {\n  ...\n}\nwhere x is the input into the function in much the same way that x is the number to be rounded in round(x = ...). It is a ‘place holder’ for the input into the function.\nStatements such as if(x == 2) are logical statements: if(...) is true then do whatever follows. If what is to be done spans over multiple lines, they are enclosed by ‘curly brackets’, {...}.\nThe statement if(x < 2 | x %% floor(x) != 0) in the function is also a logical statement with the inclusion of an or statement, denoted by |. What it is checking is whether x < 2 or if x is a fraction. Had we needed to have both conditions to be met, then an and statement would be used, denoted by & instead of |. Note that ! means not, so != tests for not equal to and is the opposite of ==, which tests for equality.\nWhere it says, 2:(x-1), this is equivalent to the function, seq(from = 2, to = (x-1), by = 1). It generates a sequence of integer numbers from \\(2\\) to \\((x-1)\\).\n\n\nCode\nx <- 10\n2 : (x - 1)\n\n\n[1] 2 3 4 5 6 7 8 9\n\n\nCode\nseq(from = 2, to = (x-1), by = 1)\n\n\n[1] 2 3 4 5 6 7 8 9\n\n\nifelse() is another logical statement. It takes the form, ifelse(condition, a, b): if the condition is met then do a, else do b. In the prime number function it is checking whether dividing \\(x\\) by any of the numbers from \\(2\\) to \\((x-1)\\) generates a whole number.\nFinally, the function return() returns an output from the function; here, a logical vector of length 1 that is TRUE, FALSE or NA dependent upon whether \\(x\\) is or is not a prime number, or if it is not a whole number above \\(1\\).\nNote that in newer versions of R, functions can also take the form,\nf <- \\(x) {\n  ...\n}\nTherefore the following is exactly equivalent to before.\n\n\nCode\nis.prime <- \\(x) {\n  if(x == 2) return(TRUE)\n  if(x < 2 | x %% floor(x) != 0) {\n    warning(\"Please enter an integer number above 1\")\n    return(NA)\n  }\n  y <- 2:(x-1)\n  ifelse(all(x%%y > 0), return(TRUE), return(FALSE))\n}"
  },
  {
    "objectID": "base.html#objects-and-classes",
    "href": "base.html#objects-and-classes",
    "title": "Base R",
    "section": "Objects and Classes",
    "text": "Objects and Classes\nOur function that checks for a prime number is stored in the object is.prime.\n\n\nCode\nclass(is.prime)\n\n\n[1] \"function\"\n\n\nThere are other classes of object in R. Some of the most common are listed below.\n\nLogical\nThe output from the is.prime() function is an example of an object of class logical because the answer is TRUE or FALSE (or NA, not applicable).\n\n\nCode\nx <- is.prime(10)\nprint(x)\n\n\n[1] FALSE\n\n\nCode\nclass(x)\n\n\n[1] \"logical\"\n\n\nSome other examples:\n\n\nCode\ny <- 10 > 5\nprint(y)\n\n\n[1] TRUE\n\n\nCode\nclass(y)\n\n\n[1] \"logical\"\n\n\nCode\nz <- 2 == 5   # is 2 equal to 5?\nprint(z)\n\n\n[1] FALSE\n\n\n\n\nNumeric\nWe have already seen that some objects are numeric.\n\n\nCode\nx <- mean(0:100)\nprint(x)\n\n\n[1] 50\n\n\nCode\nclass(x)\n\n\n[1] \"numeric\"\n\n\nThis presently is of type double; i.e. it allows for decimal places even where they are not required.\n\n\nCode\ntypeof(x)\n\n\n[1] \"double\"\n\n\nbut it could be converted to class integer (a whole number with no decimal places).\n\n\nCode\nx <- as.integer(x)\nclass(x)\n\n\n[1] \"integer\"\n\n\n\n\nCharacter\nOther classes include character. Note the difference between the length() of a character vector and the number of characters, nchar(), that any element of that vector contains.\n\n\nCode\nx <- \"Mapping and Modelling in R\"\nprint(x)\n\n\n[1] \"Mapping and Modelling in R\"\n\n\nCode\nlength(x)   # There is only one element in this vector\n\n\n[1] 1\n\n\nCode\nnchar(x)    # And that element contains 26 letters\n\n\n[1] 26\n\n\nCode\nclass(x)\n\n\n[1] \"character\"\n\n\nCode\ny <- paste(x, \"with Richard Harris\")\nprint(y)\n\n\n[1] \"Mapping and Modelling in R with Richard Harris\"\n\n\nCode\nlength(y)   # There is still only one element\n\n\n[1] 1\n\n\nCode\nnchar(y)    # But now it contains more letters\n\n\n[1] 46\n\n\nCode\nclass(y)\n\n\n[1] \"character\"\n\n\nCode\nz <- unlist(strsplit(x, \" \"))\nprint(z)\n\n\n[1] \"Mapping\"   \"and\"       \"Modelling\" \"in\"        \"R\"        \n\n\nCode\nlength(z)   # The initial vectors has been split into 5 parts\n\n\n[1] 5\n\n\nCode\nnchar(z)\n\n\n[1] 7 3 9 2 1\n\n\nCode\nclass(z)\n\n\n[1] \"character\"\n\n\n\nAs the name suggests, print is a function that prints its contents to screen. Often it can be omitted in favour of referencing the object directly. For instance, in the example above, rather than typing print(z) it would be sufficient just to type z. Just occasionally though you will find that an object does not print as you intended when the function is omitted. If this happens, try putting print back in.\n\n\nMatrix\nAn example of a matrix is\n\n\nCode\nx <- matrix(1:9, ncol = 3)\nx\n\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nCode\nncol(x)   # Number of columns\n\n\n[1] 3\n\n\nCode\nnrow(x)   # Number of rows\n\n\n[1] 3\n\n\nCode\nclass(x)\n\n\n[1] \"matrix\" \"array\" \n\n\nHere the argument byrow is changed from its default value of FALSE to be TRUE:\n\n\nCode\ny <- matrix(1:9, ncol = 3, byrow = TRUE)\n\n\nThis result is equivalent to the transpose of the original matrix.\n\n\nCode\ny\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\nCode\nt(x)\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\n\nData frame\nA data.frame is a table of data, such as,\n\n\nCode\ndf <- data.frame(Day = c(\"Mon\", \"Tues\", \"Wed\", \"Thurs\", \"Fri\", \"Sat\", \"Sun\"),\n                 Date = 20:26,\n                 Month = \"June\",\n                 Year = 2022)\ndf\n\n\n    Day Date Month Year\n1   Mon   20  June 2022\n2  Tues   21  June 2022\n3   Wed   22  June 2022\n4 Thurs   23  June 2022\n5   Fri   24  June 2022\n6   Sat   25  June 2022\n7   Sun   26  June 2022\n\n\nCode\nclass(df)\n\n\n[1] \"data.frame\"\n\n\nCode\nncol(df)    # Number of columns\n\n\n[1] 4\n\n\nCode\nnrow(df)    # Number of rows\n\n\n[1] 7\n\n\nCode\nlength(df)  # The length is also the number of columns\n\n\n[1] 4\n\n\nCode\nnames(df)   # The names of the variables in the data frame\n\n\n[1] \"Day\"   \"Date\"  \"Month\" \"Year\" \n\n\nNote that the length of each column should be equal in the specification of the data frame. The following will generate an error because the Date column is now too short. You might wonder why the Month and Year columns were fine previously when, in fact, they were give only one value, whereas there are 7 days and 7 dates. It is because R recycled them the requisite number of times (i.e. it gave all the rows the same value for Month and Year – it recycled June and 2022 seven times). That option isn’t available for the example below where there are 7 days but 6 dates.\n# This will generate an error\ndf <- data.frame(Day = c(\"Mon\", \"Tues\", \"Wed\", \"Thurs\", \"Fri\", \"Sat\", \"Sun\"),\n                 Date = 20:25,\n                 Month = \"June\",\n                 Year = 2022)\n\n\nFactors\nEarlier versions of R would, by default, convert character fields in a data frame into factors. The equivalent operation now is,\n\n\nCode\ndf2 <- data.frame(Day = c(\"Mon\", \"Tues\", \"Wed\", \"Thurs\", \"Fri\", \"Sat\", \"Sun\"),\n                 Date = 20:26,\n                 Month = \"June\",\n                 Year = 2022, stringsAsFactors = TRUE)\n\n\nTreating character fields as factors was clever but frustrating if you didn’t realise it was happening and wanted the characters to remains as characters. The difference is not immediately obvious,\n\n\nCode\nhead(df, n= 2)    # with stringsAsFactors = FALSE (the current default)\n\n\n   Day Date Month Year\n1  Mon   20  June 2022\n2 Tues   21  June 2022\n\n\nCode\nhead(df2, n = 2)  # with stringsAsFactors = TRUE  (the historic default)\n\n\n   Day Date Month Year\n1  Mon   20  June 2022\n2 Tues   21  June 2022\n\n\nThese appear to be the same but differences begin to be apparent in the following:\n\n\nCode\ndf$Day\n\n\n[1] \"Mon\"   \"Tues\"  \"Wed\"   \"Thurs\" \"Fri\"   \"Sat\"   \"Sun\"  \n\n\nCode\ndf2$Day\n\n\n[1] Mon   Tues  Wed   Thurs Fri   Sat   Sun  \nLevels: Fri Mon Sat Sun Thurs Tues Wed\n\n\nCode\ndf$Month\n\n\n[1] \"June\" \"June\" \"June\" \"June\" \"June\" \"June\" \"June\"\n\n\nCode\ndf2$Month\n\n\n[1] June June June June June June June\nLevels: June\n\n\nBasically, a factor is a categorical variable: it encodes which groups or categories (which levels) are to be found in the variable. Knowing this, it is possible to count the number of each group, as in,\n\n\nCode\nsummary(df2)\n\n\n    Day         Date       Month        Year     \n Fri  :1   Min.   :20.0   June:7   Min.   :2022  \n Mon  :1   1st Qu.:21.5            1st Qu.:2022  \n Sat  :1   Median :23.0            Median :2022  \n Sun  :1   Mean   :23.0            Mean   :2022  \n Thurs:1   3rd Qu.:24.5            3rd Qu.:2022  \n Tues :1   Max.   :26.0            Max.   :2022  \n Wed  :1                                         \n\n\nbut not\n\n\nCode\nsummary(df)\n\n\n     Day                 Date         Month                Year     \n Length:7           Min.   :20.0   Length:7           Min.   :2022  \n Class :character   1st Qu.:21.5   Class :character   1st Qu.:2022  \n Mode  :character   Median :23.0   Mode  :character   Median :2022  \n                    Mean   :23.0                      Mean   :2022  \n                    3rd Qu.:24.5                      3rd Qu.:2022  \n                    Max.   :26.0                      Max.   :2022  \n\n\n Factors can be useful but do not always behave as you might anticipate. For example,\n\n\nCode\nx <- c(\"2021\", \"2022\")\nas.numeric(x)\n\n\n[1] 2021 2022\n\n\nis different from,\n\n\nCode\nx <- factor(c(\"2021\", \"2022\"))\nas.numeric(x)\n\n\n[1] 1 2\n\n\nThese days the defult is stringsAsFactors = FALSE, which is better when using functions such as read.csv() to read a .csv file into a data.frame in R.\n\n\nLists\nA list is a more flexible class that can hold together other types of object. Without a list, the following only works because the 1:3 are coerced from numbers in x to characters in y – note the \" \" that appear around them, which shows they are now text.\n\n\nCode\nx <- as.integer(1:3)\nclass(x)\n\n\n[1] \"integer\"\n\n\nCode\ny <- c(\"a\", x)\ny\n\n\n[1] \"a\" \"1\" \"2\" \"3\"\n\n\nCode\nclass(y)\n\n\n[1] \"character\"\n\n\nOn the other hand,\n\n\nCode\ny <- list(\"a\", x)\n\n\ncreates a ragged list of two parts:\n\n\nCode\nclass(y)\n\n\n[1] \"list\"\n\n\nCode\ny\n\n\n[[1]]\n[1] \"a\"\n\n[[2]]\n[1] 1 2 3\n\n\nThe first part has the character \"a\" in it.\n\n\nCode\ny[[1]]\n\n\n[1] \"a\"\n\n\nCode\nclass(y[[1]])\n\n\n[1] \"character\"\n\n\nThe second has the numbers 1 to 3 in it.\n\n\nCode\ny[[2]]\n\n\n[1] 1 2 3\n\n\nCode\nclass(y[[2]])\n\n\n[1] \"integer\"\n\n\nNote that the length of the list is the length of its parts. Presently it is 2 but the following example has a length of three.\n\n\nCode\ny <- list(\"a\", x, df)\ny\n\n\n[[1]]\n[1] \"a\"\n\n[[2]]\n[1] 1 2 3\n\n[[3]]\n    Day Date Month Year\n1   Mon   20  June 2022\n2  Tues   21  June 2022\n3   Wed   22  June 2022\n4 Thurs   23  June 2022\n5   Fri   24  June 2022\n6   Sat   25  June 2022\n7   Sun   26  June 2022\n\n\nCode\nlength(y)\n\n\n[1] 3\n\n\n This should not be confused with the length of any one part.\n\n\nCode\nlength(y[[1]])\n\n\n[1] 1\n\n\nCode\nlength(y[[2]])\n\n\n[1] 3\n\n\nCode\nlength(y[[3]])\n\n\n[1] 4"
  },
  {
    "objectID": "base.html#assignments",
    "href": "base.html#assignments",
    "title": "Base R",
    "section": "Assignments",
    "text": "Assignments\nThroughout this document I have used the assignment term <- to store the output of a function, as in x <- as.integer(1:3) and y <- list(\"a\", x, df), and so forth. The <- is used to assign the result of a function to an object. You can, if you prefer use =. For example, all the following make the same assignment, which is to give x the value of 1.\n\n\nCode\nx <- 1\nx = 1\n1 -> x\n\n\nPersonally, I avoid using = as an assignment for the following reasons.  First, not to confuse assignments with arguments,\n\n\nCode\nx <- round(10.32, digits = 1)   # I think this is a bit clearer\nx = round(10.32, digits = 1)    # and this a bit less so\n\n\nSecond, to not confuse assignments with logical statements,\n\n\nCode\nx <- 1\ny <- 2\nz <- x == y   # Again, this is a bit clearer\nz = x == y    # and this not so much\n\n\nThird – but this is pedantic – to avoid the following sort of situation which makes no sense mathematically…\n\n\nCode\nx = 1\ny = 2\nx = y\n\n\n… but does in terms of what it really means:\n\n\nCode\nx <- 1\ny <- 2\nx <- y # Assign the value of y to x, overwriting its previous value\n\n\n Which you use is a matter of personal preference and, of course, = has one less character than <- to worry about. However, this course is written with,\n<- (or ->) is as assignment, as in x <- 1;\n= is the value of an argument, as in round(x, digits = 1); and\n== is a logical test for equality, as in x == y.\n\nIt is important to remember that R is case sensitive. An object called x is different from one called X; y is not the same as Y and so forth."
  },
  {
    "objectID": "base.html#manipulating-objects",
    "href": "base.html#manipulating-objects",
    "title": "Base R",
    "section": "Manipulating objects",
    "text": "Manipulating objects\nIn addition to passing objects to functions such as…\n\n\nCode\nx <- 0:100\nmean(x)\n\n\n[1] 50\n\n\nCode\nsum(x)\n\n\n[1] 5050\n\n\nCode\nsummary(x)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0      25      50      50      75     100 \n\n\nCode\nmedian(x)\n\n\n[1] 50\n\n\nCode\nquantile(x, probs = c(0, 0.25, 0.5, 0.75, 1))\n\n\n  0%  25%  50%  75% 100% \n   0   25   50   75  100 \n\n\nCode\nhead(sqrt(x)) # The square roots of the first of x\n\n\n[1] 0.000000 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nCode\ntail(x^2)     # The square roots of the last of x\n\n\n[1]  9025  9216  9409  9604  9801 10000\n\n\nCode\nsd(x)         # The standard deviation of x\n\n\n[1] 29.30017\n\n\n…there are other ways we may wish to interact with objects.\n\nMathematical operations\nMathematical operations generally operate on a pairwise basis between corresponding elements in a vector. For example,\n\n\nCode\nx <- 1\ny <- 3\nx + y\n\n\n[1] 4\n\n\nCode\nx <- 1:5\ny <- 6:10\nx + y\n\n\n[1]  7  9 11 13 15\n\n\nCode\nx * y   # Multiplication\n\n\n[1]  6 14 24 36 50\n\n\nCode\nx / y   # Divisions\n\n\n[1] 0.1666667 0.2857143 0.3750000 0.4444444 0.5000000\n\n\nIf one vector is shorter that the other, values will be recycled. In the following example the results are \\(1\\times6\\), \\(2\\times7\\), \\(3\\times8\\), \\(4\\times9\\) and then \\(5\\times6\\) as y is recycled.\n\n\nCode\nx <- 1:5  # This is a vector of length 5\ny <- 6:9  # This is a vector of length 4\nx * y     # A vector of length 5 but some of y is recycled\n\n\n[1]  6 14 24 36 30\n\n\n\n\nSubsets of objects\n\nVectors\nIf x is a vector then x[n] is the nth element in the vector (the nth position, the nth item). To illustrate,\n\n\nCode\nx <- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\nx[1]\n\n\n[1] \"a\"\n\n\nCode\nx[3]\n\n\n[1] \"c\"\n\n\nCode\nx[c(1, 3, 5)]\n\n\n[1] \"a\" \"c\" \"e\"\n\n\nCode\nx[length(x)]\n\n\n[1] \"f\"\n\n\nThe notation -n can be used to exclude elements.\n\n\nCode\nx[-3]   # All of x except the 3rd element\n\n\n[1] \"a\" \"b\" \"d\" \"e\" \"f\"\n\n\nCode\nx[c(-1, -3, -5)]    # x without the 1st, 3rd and 5th elements\n\n\n[1] \"b\" \"d\" \"f\"\n\n\n\n\nMatrices\nIf x is a matrix then x[i, j] is the value of the ith row of the jth column:\n\n\nCode\nx <- matrix(1:10, ncol = 2)\nx\n\n\n     [,1] [,2]\n[1,]    1    6\n[2,]    2    7\n[3,]    3    8\n[4,]    4    9\n[5,]    5   10\n\n\nCode\nx[1, 1]     # row 1, column 1\n\n\n[1] 1\n\n\nCode\nx[2, 1]     # row 2, column 1\n\n\n[1] 2\n\n\nCode\nx[c(3, 5), 2]   # rows 3 and 5 of column 2\n\n\n[1]  8 10\n\n\nCode\nx[nrow(x), ncol(x)]   # the final entry in the matrix\n\n\n[1] 10\n\n\n All of the values in the ith row can be selected using the form x[i, ]\n\n\nCode\nx[1, ]    # row 1\n\n\n[1] 1 6\n\n\nCode\nx[3, ]    # row 3\n\n\n[1] 3 8\n\n\nCode\nx[c(1, 5), ]  # rows 1 and 5\n\n\n     [,1] [,2]\n[1,]    1    6\n[2,]    5   10\n\n\nCode\nx[c(-1, -3), ]  # All except the 1st and 3rd rows\n\n\n     [,1] [,2]\n[1,]    2    7\n[2,]    4    9\n[3,]    5   10\n\n\nSimilarly, all of the values in the jth column can be selected using the form x[, j]\n\n\nCode\nx[ ,1]    # column 1\n\n\n[1] 1 2 3 4 5\n\n\nCode\nx[ ,2]    # column 2\n\n\n[1]  6  7  8  9 10\n\n\nCode\nx[ , 1:2]   # columns 1 and 2\n\n\n     [,1] [,2]\n[1,]    1    6\n[2,]    2    7\n[3,]    3    8\n[4,]    4    9\n[5,]    5   10\n\n\nCode\nx[-3 , 1:2]   # columns 1 and 2 except row 3\n\n\n     [,1] [,2]\n[1,]    1    6\n[2,]    2    7\n[3,]    4    9\n[4,]    5   10\n\n\n\n\nData frames\nData frames are not unlike a matrix.\n\n\nCode\ndf <- data.frame(Day = c(\"Mon\", \"Tues\", \"Wed\", \"Thurs\", \"Fri\", \"Sat\", \"Sun\"),\n                 Date = 20:26,\n                 Month = \"June\",\n                 Year = 2022)\ndf[, 1]   # The first column\n\n\n[1] \"Mon\"   \"Tues\"  \"Wed\"   \"Thurs\" \"Fri\"   \"Sat\"   \"Sun\"  \n\n\nCode\ndf[1, 1]  # The first row of the first column (Day)\n\n\n[1] \"Mon\"\n\n\nCode\ndf[2, 2]  # The second row of the second column (Date)\n\n\n[1] 21\n\n\nHowever, you can also reference the variable name directly, through the x$variable style notation,\n\n\nCode\ndf$Day\n\n\n[1] \"Mon\"   \"Tues\"  \"Wed\"   \"Thurs\" \"Fri\"   \"Sat\"   \"Sun\"  \n\n\nCode\ndf$Day[1]\n\n\n[1] \"Mon\"\n\n\nCode\ndf$Date[2]\n\n\n[1] 21\n\n\nAlternatively, if you wish, with the square brackets, using the [, \"variable\"] format.\n\n\nCode\ndf[, \"Day\"]\n\n\n[1] \"Mon\"   \"Tues\"  \"Wed\"   \"Thurs\" \"Fri\"   \"Sat\"   \"Sun\"  \n\n\nCode\ndf[1, \"Day\"]\n\n\n[1] \"Mon\"\n\n\nCode\ndf[2, \"Date\"]\n\n\n[1] 21\n\n\n\n\nLists\nWe have already seen the use of double square brackets, [[...]] to refer to a part of a list:\n\n\nCode\nx <- 1:3\ny <- list(\"a\", x, df)\ny[[1]]\n\n\n[1] \"a\"\n\n\nCode\ny[[2]]\n\n\n[1] 1 2 3\n\n\nCode\ny[[3]]\n\n\n    Day Date Month Year\n1   Mon   20  June 2022\n2  Tues   21  June 2022\n3   Wed   22  June 2022\n4 Thurs   23  June 2022\n5   Fri   24  June 2022\n6   Sat   25  June 2022\n7   Sun   26  June 2022\n\n\nThe extension to this is to be able to refer to a specific element within a part of the list by combining it with the other notation. Some examples are:\n\n\nCode\ny[[1]][1]\n\n\n[1] \"a\"\n\n\nCode\ny[[2]][3]\n\n\n[1] 3\n\n\nCode\ny[[3]]$Day\n\n\n[1] \"Mon\"   \"Tues\"  \"Wed\"   \"Thurs\" \"Fri\"   \"Sat\"   \"Sun\"  \n\n\nCode\ny[[3]]$Day[1]\n\n\n[1] \"Mon\"\n\n\nCode\ny[[3]][2, \"Date\"]\n\n\n[1] 21\n\n\n\nThe way to remember the difference between [[...]] and [...] is that the double square brackets reference a specific part of a list, for example [[3]], the third part; the single square brackets reference a position or element in a vector, such as [4], the fourth. Combining them, [[3]][4] is the 4th element of a vector where that vector forms the 3rd part of a list."
  },
  {
    "objectID": "base.html#deleting-objects-and-saving-the-workspace",
    "href": "base.html#deleting-objects-and-saving-the-workspace",
    "title": "Base R",
    "section": "Deleting objects and saving the workspace",
    "text": "Deleting objects and saving the workspace\nMy current working directory is,\n\n\nCode\ngetwd()\n\n\n[1] \"/Users/ggrjh/Dropbox/github/MandM\"\n\n\nand it contains the following objects:\n\n\nCode\nls()\n\n\n[1] \"df\"       \"df2\"      \"is.prime\" \"x\"        \"y\"        \"z\"       \n\n\nYours will be different. Remember, it can be useful to create a new project for a new collection of work that you are doing in R and then opening that project each time you start R will ensure that the working directory is that of the project.\nTo delete a specific object, use rm(),\n\n\nCode\nrm(z)\n\n\nOr, more than one,\n\n\nCode\nrm(df, df2, is.prime)\n\n\nTo save the workspace and all the objects it now contains use the save.image() function.\n\n\nCode\nsave.image(\"workspace1.RData\")\n\n\nTo delete all the objects created in your workspace, use\n\n\nCode\nrm(list=ls())\n\n\n\nIt is a good idea to save a workspace with a new filename before deleting too much from your workspace to allow you to recover it if necessary. Be especially careful if you use rm(list=ls()) as there is no undo function. The best you can do is load the workspace as it was the last time that you saved it.\nTo (re)load a workspace, use load().\n\n\nCode\nload(\"workspace1.RData\")"
  },
  {
    "objectID": "base.html#further-reading",
    "href": "base.html#further-reading",
    "title": "Base R",
    "section": "Further reading",
    "text": "Further reading\nThis short introduction to base R has really only scratched the surface. There are many books about R that provide a lot more detail but, to remind you, the manual that comes with the software is worth reading and probably the best place to start – An Introduction to R. It is thorough but also relatively short.\nDon’t worry if not everything makes sense at this stage. The best way to learn R is to put it into practice and that is what we shall be doing in later sessions."
  },
  {
    "objectID": "tidyverse.html#introduction",
    "href": "tidyverse.html#introduction",
    "title": "Tidyverse",
    "section": "Introduction",
    "text": "Introduction\nIf base R is R Classic then tidyverse is a new flavour of R, designed for data science. It consists of a collection of R packages that “share an underlying design philosophy, grammar, and data structures.”\nTidyverse is easier to demonstrate than to pin-down to some basics so let’s work through an example using both base R and tidyverse to illustrate some differences."
  },
  {
    "objectID": "tidyverse.html#to-start",
    "href": "tidyverse.html#to-start",
    "title": "Tidyverse",
    "section": "To Start",
    "text": "To Start\nIf, as suggested in ‘Getting Started’, you have created an R Project to contain all the files you create and download for this course then open it now by using File –> Open Project… from the dropdown menus in R Studio. If you have not created one then now might be a good time!\nWe will begin by downloading a data file to use. It will be downloaded to your working directory, which is the folder associated with your R Project if you are using one. You can check the working directory by using getwd() and change it using Session –> Set Working Directory or with the function setwd(dir) where dir is the chosen directory. If you have created a Project then the working directory is that of the Project.\nThe data are an extract of the Covid Data Dashboard for England in December 2021. Some prior manipulation and adjustments to those data have been undertaken for another project so treat them as indicative only. The actual reported numbers may have been changed slightly from their originals although only marginally so.\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/covid_extract.csv\", \"covid.csv\", mode = \"wb\", quiet = TRUE) \n\n\nWe also need to require(tidyverse) ready for use.\n\n\nCode\nrequire(tidyverse)\n\n\n\nIf you get a warning message saying there is no package called tidyverse then you need to install it: install.packages(\"tidyverse\", dependencies = TRUE). You will find that some people prefer to use library() instead of require(). The difference between them is subtle but you can find an argument in favour of using library() here even though I usually don’t."
  },
  {
    "objectID": "tidyverse.html#reading-in-the-data",
    "href": "tidyverse.html#reading-in-the-data",
    "title": "Tidyverse",
    "section": "Reading-in the data",
    "text": "Reading-in the data\nLet’s read-in and take a look at the data. First in base R.\n\n\nCode\ndf1 <- read.csv(\"covid.csv\")\nhead(df1)\n\n\n   MSOA11CD regionName X2021.12.04 X2021.12.11 X2021.12.18 X2021.12.25 All.Ages\n1 E02000002     London          25          48         148         176     7726\n2 E02000003     London          46          58         165         215    11246\n3 E02000004     London          24          44         100         141     6646\n4 E02000005     London          58          97         185         231    10540\n5 E02000007     London          38          94         153         205    10076\n6 E02000008     London          54         101         232         245    12777\n\n\nNow using tidyverse,\n\n\nCode\ndf2 <- read_csv(\"covid.csv\")\nslice_head(df2, n = 6)\n\n\n# A tibble: 6 × 7\n  MSOA11CD  regionName `2021-12-04` `2021-12-11` `2021-12-18` `2021-12-25`\n  <chr>     <chr>             <dbl>        <dbl>        <dbl>        <dbl>\n1 E02000002 London               25           48          148          176\n2 E02000003 London               46           58          165          215\n3 E02000004 London               24           44          100          141\n4 E02000005 London               58           97          185          231\n5 E02000007 London               38           94          153          205\n6 E02000008 London               54          101          232          245\n# ℹ 1 more variable: `All Ages` <dbl>\n\n\nThere are some similarities – for example the function read.csv reads-in a file of comma separated variables, as does read_csv. However, the output from these functions differ. First, tidyverse has, in this case, handled the names of the variables better. It has also created what is described as a tibble which is “a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not.” You can find out more about them and how they differ from traditional data frames here. Basically, they are a form of data frame that fit into tidyverse’s philosophy to try and keep ‘things’ tidy through a shared underlying design philosophy, grammar and data structures."
  },
  {
    "objectID": "tidyverse.html#selecting-and-renaming-variables",
    "href": "tidyverse.html#selecting-and-renaming-variables",
    "title": "Tidyverse",
    "section": "Selecting and renaming variables",
    "text": "Selecting and renaming variables\nWe will now: - select the regionName, 2021-12-04 and All Ages variables; - rename the second of these as cases and the third as population; - and look at the data again to check that it has worked.\nIn base R,\n\n\nCode\ndf1 <- df1[, c(\"regionName\", \"X2021.12.04\", \"All.Ages\")]\nnames(df1)[2:3] <- c(\"cases\", \"population\")\nhead(df1)\n\n\n  regionName cases population\n1     London    25       7726\n2     London    46      11246\n3     London    24       6646\n4     London    58      10540\n5     London    38      10076\n6     London    54      12777\n\n\nIn tidyverse,\n\n\nCode\ndf2 <- select(df2, regionName, `2021-12-04`, `All Ages`)\ndf2 <- rename(df2, cases = `2021-12-04`, population = `All Ages`)\nslice_head(df2, n = 6)\n\n\n# A tibble: 6 × 3\n  regionName cases population\n  <chr>      <dbl>      <dbl>\n1 London        25       7726\n2 London        46      11246\n3 London        24       6646\n4 London        58      10540\n5 London        38      10076\n6 London        54      12777\n\n\nComparing the two, the tidyverse code may be more intuitive to understand because of its use of verbs as functions: select(), rename() and so forth."
  },
  {
    "objectID": "tidyverse.html#piping",
    "href": "tidyverse.html#piping",
    "title": "Tidyverse",
    "section": "Piping",
    "text": "Piping\nNow we shall bring the two previous stages together, using what is referred to as a pipe. Without worrying about the detail, which we will return to presently, here is an example of a pipe, |> being used in base R:\n\n\nCode\nread.csv(\"covid.csv\") |>\n  (\\(x) x[, c(\"regionName\", \"X2021.12.04\", \"All.Ages\")])() -> df1\nnames(df1)[2:3] <- c(\"cases\", \"population\")\ndf1 |>\n  head()\n\n\n  regionName cases population\n1     London    25       7726\n2     London    46      11246\n3     London    24       6646\n4     London    58      10540\n5     London    38      10076\n6     London    54      12777\n\n\n\nThe above will only work if you are using R version 4.1.0 or above. You can check which version you are running by using R.Version()$version.\nHere is the same process using tidyverse and a different pipe, %>%,\n\n\nCode\nread_csv(\"covid.csv\") %>%\n  select(regionName, `2021-12-04`, `All Ages`) %>%\n  rename(cases = `2021-12-04`, population = `All Ages`) %>%\n  slice_head(n = 6)\n\n\n# A tibble: 6 × 3\n  regionName cases population\n  <chr>      <dbl>      <dbl>\n1 London        25       7726\n2 London        46      11246\n3 London        24       6646\n4 London        58      10540\n5 London        38      10076\n6 London        54      12777\n\n\nThe obvious difference here is that the tidyverse code is more elegant. But what is the pipe and what is the difference between |> in the base R code and %>% in the tidyverse example?\nA pipe is really just a way of sending (’piping`) something from one line of code to the next, to create a chain of commands (forgive the mixed metaphors). For example,\n\n\nCode\nx <- 0:10\nmean(x)\n\n\n[1] 5\n\n\nCould be calculated as\n\n\nCode\n0:10 |>\n  mean()\n\n\n[1] 5\n\n\nAs\n\n\nCode\n0:10 %>%\n  mean()\n\n\n[1] 5\n\n\nor, if you want to save on a few characters of code,\n\n\nCode\n0:10 %>%\n  mean\n\n\n[1] 5\n\n\nHowever, this won’t work:\n\n\nCode\n0:10 |>\n  mean\n\n\nThis is confusing but it is because of the different pipes, one (|>) a more recent development than the other (%>%).\nA more complicated example of piping is below. It employs the function sapply(), a variant of the function lapply(X, FUN) that takes a list X and applies the function FUN to each part of it. In the example, it is the function mean.\nHere it is without any pipes:\n\n\nCode\nx <- list(0:10, 10:20)\n  # Creates a list with two parts: the numbers 0 to 10, and 10 to 20\ny <- sapply(x, mean)\n  # Calculates the mean for each part of the list, which are 5 and 15\nsum(y)\n\n\n[1] 20\n\n\nCode\n  # Sums together the two means, giving 20\n\n\nWith pipes, the above could instead be written as\n\n\nCode\nlist(0:10, 10:20) |>\n  sapply(mean) |>\n  sum()\n\n\n[1] 20\n\n\nor as\n\n\nCode\nlist(0:10, 10:20) %>%\n  sapply(mean) %>%\n  sum()\n\n\n[1] 20\n\n\nAll three arrive at the same answer, which is 20.\nSo far, so good but what is the difference between |> and %>%? The answer is that %>% was developed before |> in the magrittr package, whereas |> is R’s new native pipe. They are often interchangeable but not always.\nAt the moment, the |> pipe is less flexible to use than %>%. Consider the following example. The final two lines of code work fine using %>% to pipe the data frame into the regression model, which is a line of best fit between the x and y values (the function lm() fits a linear model which can be used to predict a y value from a value of x).\n\n\nCode\n1:100 %>%\n  data.frame(x = ., y = 2*. + rnorm(100)) %>%\n  lm(y ~ x, data = .)\n\n\n\nCall:\nlm(formula = y ~ x, data = .)\n\nCoefficients:\n(Intercept)            x  \n     0.3165       1.9939  \n\n\n(note: the output you get will likely differ from mine because the function rnorm() adds some random variations to the data)\nHowever, it does not work with the pipe, |> because it does not recognise the place holder . that we had previously used to represent what was flowing through the pipe.\n\n\nCode\n# The following code does not work\n1:100 |>\n  data.frame(x = ., y = 2*. + rnorm(100)) |>\n  lm(y ~ x, data = .)\n\n\nTo solve the problem, the above code can be modified by wrapping the regression part in another function but the end result is rather ‘clunky’.\n\n\nCode\n1:100 |>\n  (\\(z) data.frame(x = z, y = 2*z + rnorm(100)))() |>\n  (\\(z) lm(y ~ x, data = z))() \n\n\n\nCall:\nlm(formula = y ~ x, data = z)\n\nCoefficients:\n(Intercept)            x  \n    -0.2703       2.0040  \n\n\nOver time, expect |> to be developed and to supersede %>%. For now, you are unlikely to encounter errors using %>% as a substitute for |> but you might using |> instead of %>%. In other words, %>% is the safer choice if you are unsure, although the |> is faster:\n\n\nCode\ninstall.packages(\"microbenchmark\", dependencies = TRUE)\nrequire(\"microbenchmark\")\nmicrobenchmark(\n  1:100 %>%\n    data.frame(x = ., y = 2*. + rnorm(100)) %>%\n    lm(y ~ x, data = .),\n  1:100 |>\n    (\\(z) data.frame(x = z, y = 2*z + rnorm(100)))() |>\n    (\\(z) lm(y ~ x, data = z))(),\n  times = 100\n)\n\n\n\n\nUnit: microseconds\n                                                                                                   expr\n                       1:100 %>% data.frame(x = ., y = 2 * . + rnorm(100)) %>% lm(y ~      x, data = .)\n (function(z) lm(y ~ x, data = z))((function(z) data.frame(x = z,      y = 2 * z + rnorm(100)))(1:100))\n     min       lq     mean   median       uq      max neval cld\n 244.278 253.0110 301.5222 266.7870 280.2965 3069.629   100   a\n 242.269 253.1955 274.9644 261.8055 278.9435  495.280   100   a"
  },
  {
    "objectID": "tidyverse.html#back-to-the-example",
    "href": "tidyverse.html#back-to-the-example",
    "title": "Tidyverse",
    "section": "Back to the example",
    "text": "Back to the example\nAfter that digression into piping, let’s return to our example that is comparing base R and tidyverse to read-in a table of data, select variables, rename one and, in the following, to calculate the number of COVID-19 cases per English region as a percentage of their estimated populations in the week ending 2021-12-04.\nFirst, in base R:\n\n\nCode\ndf1 <- read.csv(\"covid.csv\")\ndf1 <- df1[, c(\"regionName\", \"X2021.12.04\", \"All.Ages\")]\nnames(df1)[c(2,3)] <- c(\"cases\", \"population\")\ncases <- tapply(df1$cases, df1$regionName, sum)  # Total cases per region\ncases\n\n\n           East Midlands          East of England                   London \n                   25472                    35785                    43060 \n              North East               North West               South East \n                   10796                    31185                    62807 \n              South West            West Midlands Yorkshire and The Humber \n                   33846                    26554                    21079 \n\n\nCode\n  # This step isn't necessary but is included\n  # to show the result of the line above\npopulation <- tapply(df1$population, df1$regionName, sum)\n  # Total population per region\nrate <- round(cases / population * 100, 3)\nrate\n\n\n           East Midlands          East of England                   London \n                   0.524                    0.571                    0.479 \n              North East               North West               South East \n                   0.403                    0.423                    0.681 \n              South West            West Midlands Yorkshire and The Humber \n                   0.598                    0.445                    0.381 \n\n\nNow using tidyverse,\n\n\nCode\nread_csv(\"covid.csv\") |>\n  select(regionName, `2021-12-04`, `All Ages`) |>\n  rename(cases = `2021-12-04`, population = `All Ages`) |>\n  group_by(regionName) |>\n  summarise(across(where(is.numeric), sum)) |>\n  mutate(rate = round(cases / population * 100, 3)) |>\n  print(n = Inf)\n\n\n# A tibble: 9 × 4\n  regionName               cases population  rate\n  <chr>                    <dbl>      <dbl> <dbl>\n1 East Midlands            25472    4865583 0.524\n2 East of England          35785    6269161 0.571\n3 London                   43060    8991550 0.479\n4 North East               10796    2680763 0.403\n5 North West               31185    7367456 0.423\n6 South East               62807    9217265 0.681\n7 South West               33846    5656917 0.598\n8 West Midlands            26554    5961929 0.445\n9 Yorkshire and The Humber 21079    5526350 0.381\n\n\nEither way produces the same answers but, again, there is an elegance and consistency to the tidyverse way of doing it (which works just fine with the |> pipe) that is, perhaps, missing from base R."
  },
  {
    "objectID": "tidyverse.html#plotting",
    "href": "tidyverse.html#plotting",
    "title": "Tidyverse",
    "section": "Plotting",
    "text": "Plotting\nAs a final step for the comparison, we will extend the code to visualise the regional COVID-19 rates in a histogram, with a rug plot included. A rug plot is a way of preserving the individual data values that would otherwise be ‘lost’ within the bins of a histogram.\nAs previously, we begin with base R,\n\n\nCode\ndf1 <- read.csv(\"covid.csv\")\ndf1 <- df1[, c(\"regionName\", \"X2021.12.04\", \"All.Ages\")]\nnames(df1)[c(2,3)] <- c(\"cases\", \"population\")\ncases <- tapply(df1$cases, df1$regionName, sum)\npopulation <- tapply(df1$population, df1$regionName, sum)\nrate <- round(cases / population * 100, 3)\nhist(rate, xlab = \"rate (cases as % of population)\",\n     main = \"Regional COVID-19 rates: week ending 2021-12-04\")\nrug(rate, lwd = 2)\n\n\n\n\n\n…and continue with tidyverse, creating the output in such a way that it mimics the previous plot.\n\n\nCode\nrequire(ggplot2)\nread_csv(\"covid.csv\") |>\n  select(regionName, `2021-12-04`, `All Ages`) |>\n  rename(cases = `2021-12-04`, population = `All Ages`) |>\n  group_by(regionName) |>\n  summarise(across(where(is.numeric), sum)) |>\n  mutate(rate = round(cases / population * 100, 3)) -> df2\n\ndf2 |>\n  ggplot(aes(x = rate)) +\n    geom_histogram(colour = \"black\", fill = \"grey\", binwidth = 0.05,\n                   center = -0.025) +\n    geom_rug(linewidth = 2) +\n    labs(x = \"rate (cases as % of population)\", y = \"Frequency\",\n         title = \"Regional COVID-19 rates: week ending 2021-12-04\") +\n    theme_minimal() +\n    theme(panel.grid.major.y = element_blank())\n\n\n\n\n\nIn this instance, it is the tidyverse code that is the more elaborate. This is partly because there is more customisation of it to mimic the base R plot. However, it is also because it is using the package ggplot2 to produce the histogram. We return to ggplot2 more in later sessions. For now it is sufficient to scan the code and observe how it is ‘layering up’ the various components of the graphic, which those components separated by the + in the lines of code.\n\nThe use of the + notation in ggplot2 operates a little like a pipe in that the outcome of one operation is handed on to the next to modify the graphic being produced. It doesn’t use the pipe because the package’s origins are somewhat older but just think of the + as layering-up – adding to – the graphic.\nI prefer the ggplot2 to the hist() graphics plot but that may be a matter of personal taste. However, ggplot2 can do ‘clever things’ with the visualisation, a hint of which is shown below.\n\n\nCode\ndf2 |>\n  ggplot(aes(x = rate)) +\n    geom_histogram(colour = \"black\", fill = \"grey\", binwidth = 0.05,\n                   center = -0.025) +\n    geom_rug(aes(colour = regionName), size = 2) +\n    labs(x = \"rate (cases as % of population)\", y = \"Frequency\",\n         title = \"Regional COVID-19 rates: week ending 2021-12-04\") +\n    scale_colour_discrete(name = \"Region\") +\n    theme_minimal() +\n    theme(panel.grid.major.y = element_blank()) \n\n\n\n\n\n Please don’t form that impression that ggplot2 is hard-wired to tidverse and base R to the base graphics. In practice, they are interchangeable.\nHere is an example of using ggplot2 after a sequence of base R commands.\n\n\nCode\ndf1 <- read.csv(\"covid.csv\")\ndf1 <- df1[, c(\"regionName\", \"X2021.12.04\", \"All.Ages\")]\nnames(df1)[c(2,3)] <- c(\"cases\", \"population\")\ndf1$rate <- round(df1$cases / df1$population * 100, 3)\nggplot(df1, aes(x = rate, y = regionName)) +\n  geom_boxplot() +\n  labs(x = \"rate (cases as % of population)\",\n       y = \"region\",\n       title = \"Regional COVID-19 rates: week ending 2021-12-04\") +\n  theme_minimal()\n\n\n\n\n\nAnd here is an example of using the base R graphic boxplot() after a chain of tidyverse commands.\n\n\nCode\nread_csv(\"covid.csv\") |>\n  select(regionName, `2021-12-04`, `All Ages`) |>\n  rename(cases = `2021-12-04`, population = `All Ages`) |>\n  mutate(rate = round(cases / population * 100, 3)) -> df2\npar(mai=c(0.8,2,0.5,0.5), bty = \"n\", pch = 20)  # See text below\nboxplot(df2$rate ~ df2$regionName, horizontal = TRUE,\n        whisklty = \"solid\", staplelty = 0,\n        col = \"white\", las = 1, cex = 0.9, cex.axis = 0.75,\n        xlab = \"rate (cases as % of population)\", ylab=\"\",\n        main = \"Regional COVID-19 rates: week ending 2021-12-04\")\ntitle(ylab = \"region\", line = 6)\n\n\n\n\n\nI would argue that, in this instance, the base R graphic is as nice as the ggplot2 one but it took more customisation to get it that way and I had to go digging around in the help files, ?boxplot, ?bxp and ?par to find what I needed, which included changing the graphic’s margins (par(mai=...))), moving and changing the size of the text on the vertical axis (the argument cex.axis and the use of the title function), changing the appearance of the ‘whiskers’ (whisklty = \"solid\" and staplelty = 0), and so forth. Still, it does demonstrate that you can have a lot of control over what is produced, if you have the patience and tenacity to do so."
  },
  {
    "objectID": "tidyverse.html#which-is-better",
    "href": "tidyverse.html#which-is-better",
    "title": "Tidyverse",
    "section": "Which is better?",
    "text": "Which is better?\nHaving provided a very small taste of tidyverse and how it differs from base R, we might ask, “which is better?” However, the question is misguided: it is a little like deciding to go to South America and asking whether Spanish or Portuguese is the better language to use. It depends, of course, on what you intend to do and where you intend to travel.\nI use both base R and tidyverse packages in my work, sometimes drifting between the two in rather haphazard ways. If I can get what I want to work then I am happy. Outcomes worry me more than means so, although I use tidyverse a lot, I am not always as tidy as it would want me to be!"
  },
  {
    "objectID": "tidyverse.html#futher-reading",
    "href": "tidyverse.html#futher-reading",
    "title": "Tidyverse",
    "section": "Futher reading",
    "text": "Futher reading\n\nThere is much more to tidyverse than has been covered here. See here for further information about it and its core packages.\nA full introduction to using tidyverse for Data Science is provided by the book R for Data Science (2nd edition) by Hadley Wickham and Garrett Grolemund. There is a free online version."
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Programming",
    "section": "",
    "text": "So far in this course we have been cutting and pasting from these webpages into the Console of R Studio. Working in the Console is useful if you want to work with code on a line-by-line basis – sometimes it is helpful to see if something will work; to try things out. However, in practice, it is better to write and work with more reproducible code, either for your own benefit so you can modify something without having entirely to start-over, or for the benefit of others who would like to reproduce your work. Reproducibility is an important component of open research and is to be encouraged wherever possible."
  },
  {
    "objectID": "program.html#programming-in-r",
    "href": "program.html#programming-in-r",
    "title": "Programming",
    "section": "",
    "text": "So far in this course we have been cutting and pasting from these webpages into the Console of R Studio. Working in the Console is useful if you want to work with code on a line-by-line basis – sometimes it is helpful to see if something will work; to try things out. However, in practice, it is better to write and work with more reproducible code, either for your own benefit so you can modify something without having entirely to start-over, or for the benefit of others who would like to reproduce your work. Reproducibility is an important component of open research and is to be encouraged wherever possible."
  },
  {
    "objectID": "program.html#scripts",
    "href": "program.html#scripts",
    "title": "Programming",
    "section": "Scripts",
    "text": "Scripts\nA script is a text file containing a sequence of commands that can be run together, one after the other, without entering them separately in the Console. Let’s download an example of a script:\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/scripts/script1.R\",\n              \"script1.R\", mode = \"wb\", quiet = TRUE)\n\n\nYou can now use file.edit(\"script1.R\") to view its contents. It should look like this:\n\n The script is essentially the same code that was used previously when answering the question “why R?”, producing maps of ethnic diversity in the English cities of Birmingham, Leicester, London and Manchester. The main difference is that the maps are output to create a .pdf file rather than to screen.\nIf you now click within the window of the script and use command-A (Mac) or ctrl-A (Windows) to select all the code, followed by command-Enter/Return (Mac) or ctrl-Enter/Return (Windows) – or use the Run button towards the top-right of the script window – then the script will run in its entirety and should, at its conclusion, produce the document maps.pdf in your Working Directory.\nBe patient whilst the code takes a few moments to run.\nYou can check the document is there with,\n\n\nCode\nfile.exists(\"maps.pdf\")\n\n\n[1] TRUE\n\n\nand you should be able to open it with,\n\n\nCode\nsystem(\"open maps.pdf\")\n\n\nTry also typing source(\"script1.R\", echo = TRUE) into the R Console. Again, the script should run in its entirety."
  },
  {
    "objectID": "program.html#r-markdown",
    "href": "program.html#r-markdown",
    "title": "Programming",
    "section": "R markdown",
    "text": "R markdown\nScripts are useful but sometimes we wish to author documents that combine written text such as this with executable R code and its outputs, then to publish them as html, pdf or Word documents. This is where R Markdown is useful.\nFrom the dropdown menus, select File -&gt; New File -&gt; R Markdown. Create the document in html format and give it any title you like.\n\nAfter R Studio has created the document, Knit it. The first time you do this, you will be asked to save the document - call it markdown1.Rmd or any other name you prefer.\n\nIt is self-evident what knitting the document does – it produce an html file which includes the text and formatting, the R code (unless suppressed with echo = FALSE) and output from that code. It also includes the option to publish the document on RPubs (although I suggest you don’t do this now).\n\n This whole course is written based on R Markdown. You can download the markdown file for this session\n\n\nCode\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/markdown/programming.Rmd\", \"markdown_example.Rmd\", mode = \"wb\", quiet = TRUE)\n\n\nand view it using file.edit(\"markdown_example.Rmd\"). You may note that it begins with a YAML header, to which various arguments can be added or changed – see here for an introduction.\n---\ntitle: \"Programming\"\nauthor: \"Rich Harris\"\ndate: '2022-07-11'\noutput: html_document\n---\nIt then consists of a mixture of text and code chunks. Those code chunks can be executed within the document using the Run drop-down menus and buttons.\n\n The document also includes various syntax, including ##header for a header, **bold** for bold, ![](image.png) to insert an existing image file, and so forth. To learn more, see the R Markdown cheatsheet."
  },
  {
    "objectID": "program.html#the-source-code-for-this-document",
    "href": "program.html#the-source-code-for-this-document",
    "title": "Programming",
    "section": "The source code for this document",
    "text": "The source code for this document\nThis page has actually been authored in a variant of R markdown, using quarto. You can view the source code for this and other pages using View Source from the drop-down Code options at the top of the page."
  },
  {
    "objectID": "program.html#summary",
    "href": "program.html#summary",
    "title": "Programming",
    "section": "Summary",
    "text": "Summary\nAlthough a lot of what we will do in this course will involve cutting and pasting into the Console, keep in mind that there are better ways of programming that are more reproducible than entering commands one at a time into the Console. These include scripting and using markdown. Note also that as commands are entered into the Console, they are saved in the History to the top right of the screen. All or part of that history can be selected and moved to a source file (a new R Script) as the following shows. The history can also be saved – see ?save.history()."
  },
  {
    "objectID": "program.html#further-reading",
    "href": "program.html#further-reading",
    "title": "Programming",
    "section": "Further reading",
    "text": "Further reading\n\nThe book, Efficient R programming by Colin Gillespie and Robin Lovelace has an online version here.\nMore about R Markdown can be learned from https://rmarkdown.rstudio.com/. It is a bit advanced for this stage of the course but it is worth noting that there is a cheatsheet available."
  },
  {
    "objectID": "exercise1.html",
    "href": "exercise1.html",
    "title": "Follow-up exercise",
    "section": "",
    "text": "For this short follow-up exercise, create a simple R markdown file (I suggest in HTML output format) that, when knitted, includes the code and output for the following:\n\nTo read the following file into R: https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/diversity2.csv. The file is in .csv format. It contains headers (i.e. the top row of the data is the variable names).\nTo draw a scatterplot using the following variables in the data: E.01 as the x-axis and E.21 as the y-axis. In the plot, name the x-axis, “Diversity (2001)” and the y-axis “Diversity (2021)”. For your information, E.01 and E.21 measure the ethnic diversity of various places in England and Wales in 2001 and 2021, respectively. The measure ranges from 0 (no diversity) to 1 (‘maximum diversity’).\nTo add a reference line to the plot, with a gradient of 1 and a y-intercept of 0, showing where E.01 = E.21 (no change in diversity),\nTo add a rug plot to the plot on both axes.\n\nRun through the stages above twice in your markdown file, first using base R and the base R graphics, then second using tidyverse and ggplot**. Then add a very brief textual comment beneath your code and output interpreting the graphs in terms of whether places are becoming more ethnically diverse or not. This only needs to be a sentence or two of text, nothing longer."
  },
  {
    "objectID": "exercise1.html#to-do",
    "href": "exercise1.html#to-do",
    "title": "Follow-up exercise",
    "section": "",
    "text": "For this short follow-up exercise, create a simple R markdown file (I suggest in HTML output format) that, when knitted, includes the code and output for the following:\n\nTo read the following file into R: https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/diversity2.csv. The file is in .csv format. It contains headers (i.e. the top row of the data is the variable names).\nTo draw a scatterplot using the following variables in the data: E.01 as the x-axis and E.21 as the y-axis. In the plot, name the x-axis, “Diversity (2001)” and the y-axis “Diversity (2021)”. For your information, E.01 and E.21 measure the ethnic diversity of various places in England and Wales in 2001 and 2021, respectively. The measure ranges from 0 (no diversity) to 1 (‘maximum diversity’).\nTo add a reference line to the plot, with a gradient of 1 and a y-intercept of 0, showing where E.01 = E.21 (no change in diversity),\nTo add a rug plot to the plot on both axes.\n\nRun through the stages above twice in your markdown file, first using base R and the base R graphics, then second using tidyverse and ggplot**. Then add a very brief textual comment beneath your code and output interpreting the graphs in terms of whether places are becoming more ethnically diverse or not. This only needs to be a sentence or two of text, nothing longer."
  },
  {
    "objectID": "exercise1.html#to-help",
    "href": "exercise1.html#to-help",
    "title": "Follow-up exercise",
    "section": "To help",
    "text": "To help\nMost of the code you need to complete this task is included in the ‘Flavours of R’ section of this course. However, you may also find it useful to look at the help files for ?read.csv, ?read_csv, ?plot,?abline and ?rug, the example ggplot2 code available here, here and here, and perhaps also the ggplot2 cheatsheet. You might also look at this introduction to R Markdown but it covers more about R Markdown than you need at this stage. Simply creating a new document using File -&gt; New File -&gt; R Markdown… should be sufficient to get you started."
  },
  {
    "objectID": "themap.html",
    "href": "themap.html",
    "title": "The Spatial Variable",
    "section": "",
    "text": "When we look at a map such as the following, which is a choropleth (or thematic) map showing the percentage of the population with no experience of schooling in each of the South African municipalities in 2011, one thing should be immediately obvious: the areas are shaded in a range of colours; they are not all the same. This is because the values that the colours represent vary across the country with some places having a greater percentage of their population without schooling than others. In this way, the map reveals and also visually represents the spatial (geographic) variation in the variable of interest. The map portrays the geographic pattern. Knowing something about the pattern might provide information about the processes that generated the pattern. At a minimum, it can reveal socio-spatial inequalities in an outcome of interest across a study region.\n\nIt is not surprising to find spatial variation. It is improbable that all the values would be the same. It is nearly always possible to find that some places have lower or higher values than others and to colour the map accordingly. Nevertheless, three characteristics of the spatial variation appear evident in the map.\n\nSpatial heterogeneity. This is the idea that the values typical in one part of the map are not typical in another. To put it simply, some parts of the map are shaded in blue whereas others are in red and those parts seem neither randomly nor regularly distributed because of…\nSpatial clustering. This is the idea that values found in one part of the map tend to be surrounded by similar values in neighbouring parts of the map. In other words, there are patches of blue and patches of red coloured areas on the map – blue tends be near blue and red tends to be near red. Another name for this is positive spatial autocorrelation: values tend to be more similar to nearby other values than they are to distant ones.\n\nEvidence of spatial clustering supports Waldo Tobler’s much cited ‘first law’ of geography: “everything is related to everything else, but near things are more related than distant things.” However, it isn’t really a law because it is by no means always true. If we look at the map, we can also see,\n\nSpatial discontinuities (negative spatial autocorrelation) because sometimes neighbouring places can have very different characteristics – there there can be sharp changes across borders (red next to blue).\n\nNevertheless, Tobler’s ‘law’ does suggest that places tend to be situated within broader spatial contexts such that the processes that both generate and are generated by those contexts have a spatial expression and root\nTaken together, these characteristics of spatial variation indicate spatial dependencies, whereby the measured attributes of one place are not independent of other places. This dependence has statistical consequences if assumptions of independence are violated. Of more substantive geographic interest is how they have arisen – which processes are they caused by or associated with? Why are places not all the same? Why is there a geographical pattern? Complicating the answers to these questions is that what we see in the map is not just a function of underlying social or other processes but also the ways the data are collected and the map constructed. For example, the geographic scale of the data and where the boundaries are drawn between places. This is the Modifiable Areal Unit Problem (MAUP)."
  },
  {
    "objectID": "themap.html#introduction",
    "href": "themap.html#introduction",
    "title": "The Spatial Variable",
    "section": "",
    "text": "When we look at a map such as the following, which is a choropleth (or thematic) map showing the percentage of the population with no experience of schooling in each of the South African municipalities in 2011, one thing should be immediately obvious: the areas are shaded in a range of colours; they are not all the same. This is because the values that the colours represent vary across the country with some places having a greater percentage of their population without schooling than others. In this way, the map reveals and also visually represents the spatial (geographic) variation in the variable of interest. The map portrays the geographic pattern. Knowing something about the pattern might provide information about the processes that generated the pattern. At a minimum, it can reveal socio-spatial inequalities in an outcome of interest across a study region.\n\nIt is not surprising to find spatial variation. It is improbable that all the values would be the same. It is nearly always possible to find that some places have lower or higher values than others and to colour the map accordingly. Nevertheless, three characteristics of the spatial variation appear evident in the map.\n\nSpatial heterogeneity. This is the idea that the values typical in one part of the map are not typical in another. To put it simply, some parts of the map are shaded in blue whereas others are in red and those parts seem neither randomly nor regularly distributed because of…\nSpatial clustering. This is the idea that values found in one part of the map tend to be surrounded by similar values in neighbouring parts of the map. In other words, there are patches of blue and patches of red coloured areas on the map – blue tends be near blue and red tends to be near red. Another name for this is positive spatial autocorrelation: values tend to be more similar to nearby other values than they are to distant ones.\n\nEvidence of spatial clustering supports Waldo Tobler’s much cited ‘first law’ of geography: “everything is related to everything else, but near things are more related than distant things.” However, it isn’t really a law because it is by no means always true. If we look at the map, we can also see,\n\nSpatial discontinuities (negative spatial autocorrelation) because sometimes neighbouring places can have very different characteristics – there there can be sharp changes across borders (red next to blue).\n\nNevertheless, Tobler’s ‘law’ does suggest that places tend to be situated within broader spatial contexts such that the processes that both generate and are generated by those contexts have a spatial expression and root\nTaken together, these characteristics of spatial variation indicate spatial dependencies, whereby the measured attributes of one place are not independent of other places. This dependence has statistical consequences if assumptions of independence are violated. Of more substantive geographic interest is how they have arisen – which processes are they caused by or associated with? Why are places not all the same? Why is there a geographical pattern? Complicating the answers to these questions is that what we see in the map is not just a function of underlying social or other processes but also the ways the data are collected and the map constructed. For example, the geographic scale of the data and where the boundaries are drawn between places. This is the Modifiable Areal Unit Problem (MAUP)."
  },
  {
    "objectID": "themap.html#from-the-map-towards-models",
    "href": "themap.html#from-the-map-towards-models",
    "title": "The Spatial Variable",
    "section": "From the map towards models",
    "text": "From the map towards models\nWith the above questions in mind, we might imagine the map as a first stage in a process of geographical enquiry where what we do is look for and then quantify some of the geographical patterns in the data before beginning to model them and to look for correlates, associations and causes. Here the map is not simply a tool for visualising and communicating data, it is also a tool for exploring data and thinking geographically about them.\n\n\n\n\n\n\n In practice, the process of analysis is likely to involve greater cycling between the various stages. Nevertheless, there is a good argument for starting with the map.\n\n\n\n\n\n\nThe point is that the map serves both as a representation of ‘the spatial variable’ and as a tool for understanding it."
  },
  {
    "objectID": "themap.html#further-reading",
    "href": "themap.html#further-reading",
    "title": "The Spatial Variable",
    "section": "Further Reading",
    "text": "Further Reading\nThe Spatial Variable was the name of the inaugural lecture given by Ron Johnston, one of the most influential geographers of recent times, on his appointment as Professor at the University of Sheffield. A transcript and brief commentary on that lecture is available here and is highly recommended reading."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "The lecture presentations for the course are available to view below.\nLecture 1. Introduction to the course\n\nThis is a work in progress\nAdditional lectures will be added as they become available."
  },
  {
    "objectID": "thematicmaps.html",
    "href": "thematicmaps.html",
    "title": "Thematic maps in R",
    "section": "",
    "text": "There are lots of ways to produce maps in R. But, however, they are drawn, two things are usually needed to produce a choropleth map of the sort seen in previous sessions:\n\nfirst, some data;\nsecond, a map to join the data to.\n\nThe join is usually made possible by the data and the map containing the same variable; for example, using the same ID codes for all the places in the data as in the map. This implies that what is contained in the data set are measurements of the places shown in the map. Sometimes maps will come pre-bundled with the data of interest so, in effect, the join has already been made.\nOnce we have the data ready to map then R offers plenty of options to produce quick or publication quality maps, which may have either static or dynamic content. The two packages we shall focus on are:\n\nggplot2 (mainly in Part 1) and\ntmap (mainly in Part 2).\n\nHowever, there are others. Notably, what we are looking at in this exercise are vector data – data for which the geography is ultimately defined by a series of points (two points define a line, a series of lines define a boundary, a boundary demarcates an area). The other common geographic representation used in Geographic Information Systems is as a series of raster cells (a grid overlaid upon an area, which each cell in the grid given one or more values), for which the stars and raster packages are useful.\nAnother package we shall be using in this session is sf, which provides “support for simple features, a standardized way to encode spatial vector data.”"
  },
  {
    "objectID": "thematicmaps.html#introduction",
    "href": "thematicmaps.html#introduction",
    "title": "Thematic maps in R",
    "section": "",
    "text": "There are lots of ways to produce maps in R. But, however, they are drawn, two things are usually needed to produce a choropleth map of the sort seen in previous sessions:\n\nfirst, some data;\nsecond, a map to join the data to.\n\nThe join is usually made possible by the data and the map containing the same variable; for example, using the same ID codes for all the places in the data as in the map. This implies that what is contained in the data set are measurements of the places shown in the map. Sometimes maps will come pre-bundled with the data of interest so, in effect, the join has already been made.\nOnce we have the data ready to map then R offers plenty of options to produce quick or publication quality maps, which may have either static or dynamic content. The two packages we shall focus on are:\n\nggplot2 (mainly in Part 1) and\ntmap (mainly in Part 2).\n\nHowever, there are others. Notably, what we are looking at in this exercise are vector data – data for which the geography is ultimately defined by a series of points (two points define a line, a series of lines define a boundary, a boundary demarcates an area). The other common geographic representation used in Geographic Information Systems is as a series of raster cells (a grid overlaid upon an area, which each cell in the grid given one or more values), for which the stars and raster packages are useful.\nAnother package we shall be using in this session is sf, which provides “support for simple features, a standardized way to encode spatial vector data.”"
  },
  {
    "objectID": "thematicmaps.html#getting-started",
    "href": "thematicmaps.html#getting-started",
    "title": "Thematic maps in R",
    "section": "Getting Started",
    "text": "Getting Started\nAs in previous sessions, if you are keeping all the files and outputs from these exercises together in an R Project (which is a good idea) then open that Project now.\n\nLoad the data\nLet’s begin with the easy bit and load the data, which are from http://superweb.statssa.gov.za. These includes the variable No_schooling which is the percentage of the population without schooling per South African municipality in 2011.\n\n\nCode\n# A quick check to see if the Tidyverse packages are installed...\ninstalled &lt;- installed.packages()[,1]\nif(!(\"tidyverse\" %in% installed)) install.packages(\"tidyverse\",\n                                                   dependencies = TRUE)\nrequire(tidyverse)\n\n# Read-in the data directly from a web location. The data are in .csv format\neducation &lt;- read_csv(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/education.csv\")\n# Quick check of the data by looking at the top three rows\nslice_head(education, n = 3)\n\n\n# A tibble: 3 × 8\n  LocalMunicipalityCode LocalMunicipalityName No_schooling Some_primary\n  &lt;chr&gt;                 &lt;chr&gt;                        &lt;dbl&gt;        &lt;dbl&gt;\n1 EC101                 Camdeboo                      13.4         34.5\n2 EC102                 Blue Crane Route              16.0         36.2\n3 EC103                 Ikwezi                        18.4         35.4\n# ℹ 4 more variables: Complete_primary &lt;dbl&gt;, Some_secondary &lt;dbl&gt;,\n#   Grade_12_Std_10 &lt;dbl&gt;, Higher &lt;dbl&gt;\n\n\n\n\nLoading the map\nNext we need a ‘blank map’ of the same South African municipalities that are included in the data above. It is read-in below in geoJSON format but it would not have been unusual if it had been in .shp (shapefile) or .kml format, instead. The source of the data is https://dataportal-mdb-sa.opendata.arcgis.com/. There are several ways of reading this file into R but it is better to use the sf package because older options such as maptools::readShapePoly() (which was for reading shapefiles) or rgdal::readOGR are either deprecated already or in the process of being retired.\n\n\nCode\n# Another quick check to make sure that various libraries have been installed\nif(!(\"proxy\" %in% installed)) install.packages(\"proxy\")\nif(!(\"sf\" %in% installed)) install.packages(\"sf\", dependencies = TRUE)\nrequire(sf)\n\n# Use the read_sf() function from the sf library to read in a digital map of the study area\nmunicipal &lt;- read_sf(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/boundary%20files/MDB_Local_Municipal_Boundary_2011.geojson\")\n\n\n If we now look at the top of the municipal object then we find it is of class sf, which is short for simple features. It has a vector geometry (it is of type multipolygon) and has its coordinate reference system (CRS) set as WGS 84. It also contains some attribute data, although not the schooling data we are looking to map.\n\n\nCode\nslice_head(municipal, n = 1)\n\n\nSimple feature collection with 1 feature and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 27.15761 ymin: -33.28488 xmax: 28.0811 ymax: -32.67573\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 11\n  OBJECTID ProvinceCode ProvinceName LocalMunicipalityCode LocalMunicipalityName\n     &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;                 &lt;chr&gt;                \n1        1 EC           Eastern Cape BUF                   Buffalo City         \n# ℹ 6 more variables: DistrictMunicipalityCode &lt;chr&gt;,\n#   DistrictMunicipalityName &lt;chr&gt;, Year &lt;int&gt;, Shape__Area &lt;dbl&gt;,\n#   Shape__Length &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nHere are just the attribute data\n\n\nCode\nst_drop_geometry(municipal) |&gt;\n  slice_head(n = 5)\n\n\n# A tibble: 5 × 10\n  OBJECTID ProvinceCode ProvinceName LocalMunicipalityCode LocalMunicipalityName\n     &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;                 &lt;chr&gt;                \n1        1 EC           Eastern Cape BUF                   Buffalo City         \n2        2 EC           Eastern Cape EC101                 Camdeboo             \n3        3 EC           Eastern Cape EC102                 Blue Crane Route     \n4        4 EC           Eastern Cape EC103                 Ikwezi               \n5        5 EC           Eastern Cape EC104                 Makana               \n# ℹ 5 more variables: DistrictMunicipalityCode &lt;chr&gt;,\n#   DistrictMunicipalityName &lt;chr&gt;, Year &lt;int&gt;, Shape__Area &lt;dbl&gt;,\n#   Shape__Length &lt;dbl&gt;\n\n\nAnd here is the ‘blank’ map, drawn using plot{sf}, which is the ‘base’ way of plotting sf objects.\n\n\nCode\npar(mai=c(0, 0, 0, 0))  # Removes the plot margins\nmunicipal |&gt;\n  st_geometry() |&gt;\n  plot()\n\n\n\n\n\nHad it been necessary to set the coordinate reference system (CRS) then the function st_set_crs() would be used. Instead, and just for fun, we will change the existing CRS: here is the map transformed on to a ‘south up’ coordinate reference system, achieved by changing its EPSG code to 2050 with the function st_transform().\n\n\nCode\npar(mai=c(0, 0, 0, 0))\nmunicipal |&gt;\n  st_transform(2050) |&gt;\n  st_geometry() |&gt;\n  plot()\n\n\n\n\n\n\nNote how functions with the sf library tend to start with st_. Personally, I find this slightly confusing and I am not sure it doesn’t make it harder to find what I looking for in the package’s help pages but it is consistent for the functions and methods that operate on spatial data and is, I believe, short for spatial type.\n\n\nsf and sp\nAt the risk of over-simplification, sf (simple features) can be viewed as a successor to the earlier sp (spatial) and related packages, which are well documented in the book Applied Spatial Data Analysis with R. Sometimes other packages are still reliant on sp and so the spatial objects need to be changed into sp’s native format prior to use.\n\n\nCode\n# From sf to sp\nmunicipal_sp &lt;- as(municipal, \"Spatial\")\nclass(municipal_sp)\n\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nCode\n# From sp to sf\nmunicipal_sf &lt;- st_as_sf(municipal_sp)\nclass(municipal_sf)\n\n\n[1] \"sf\"         \"data.frame\""
  },
  {
    "objectID": "thematicmaps.html#joining-the-attribute-data-to-the-map",
    "href": "thematicmaps.html#joining-the-attribute-data-to-the-map",
    "title": "Thematic maps in R",
    "section": "Joining the attribute data to the map",
    "text": "Joining the attribute data to the map\nIf we look again at the map and schooling data, we find that they have two variables in common which suggests a means to join them together based on a common variable.\n\n\nCode\n# The variables that they appear to have in common...\nintersect(names(municipal), names(education))\n\n\n[1] \"LocalMunicipalityCode\" \"LocalMunicipalityName\"\n\n\nThis is encouraging but, in this example, we need to be careful using the municipal names because not all of those in the map are in the education data or vice versa. Although the variable LocalMunicipalityName is present in both the map and education data, the variable is not actually the same in both because of different ways of spelling the names of places.\n\n\nCode\n# anti_join() returns all rows from x without a match in y\nanti_join(municipal, education, by = \"LocalMunicipalityName\")\n\n\nSimple feature collection with 7 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 27.42423 ymin: -32.05935 xmax: 32.05014 ymax: -24.96652\nGeodetic CRS:  WGS 84\n# A tibble: 7 × 11\n  OBJECTID ProvinceCode ProvinceName LocalMunicipalityCode LocalMunicipalityName\n     &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;                 &lt;chr&gt;                \n1       34 EC           Eastern Cape EC157                 King Sabata Dalindye \n2       74 KZN          KwaZulu-Nat… KZN214                uMuziwabantu         \n3       75 KZN          KwaZulu-Nat… KZN215                Ezinqoleni           \n4       97 KZN          KwaZulu-Nat… KZN262                uPhongolo            \n5      146 MP           Mpumalanga   MP301                 Chief Albert Luthuli \n6      149 MP           Mpumalanga   MP304                 Dr Pixley Ka Isaka S \n7      165 NW           North West   NW372                 Local Municipality o \n# ℹ 6 more variables: DistrictMunicipalityCode &lt;chr&gt;,\n#   DistrictMunicipalityName &lt;chr&gt;, Year &lt;int&gt;, Shape__Area &lt;dbl&gt;,\n#   Shape__Length &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\nCode\nanti_join(education, municipal, by = \"LocalMunicipalityName\")\n\n\n# A tibble: 7 × 8\n  LocalMunicipalityCode LocalMunicipalityName  No_schooling Some_primary\n  &lt;chr&gt;                 &lt;chr&gt;                         &lt;dbl&gt;        &lt;dbl&gt;\n1 EC157                 King Sabata Dalindyebo         21.7         33.2\n2 KZN214                UMuziwabantu                   20.7         42.1\n3 KZN215                Ezingoleni                     21.9         40.1\n4 KZN262                UPhongolo                      22.5         35.1\n5 MP301                 Albert Luthuli                 23.8         31.1\n6 MP304                 Pixley Ka Seme                 24.0         31.9\n7 NW372                 Madibeng                       12.8         27.1\n# ℹ 4 more variables: Complete_primary &lt;dbl&gt;, Some_secondary &lt;dbl&gt;,\n#   Grade_12_Std_10 &lt;dbl&gt;, Higher &lt;dbl&gt;\n\n\nFortunately, the municipal codes are consistent even where the names are not, which is why place codes and IDs are generally better than using names when joining data.\n\n\nCode\n# The municipality codes are consistent in the map and data; there are none that do not match.=\nanti_join(municipal, education, by = \"LocalMunicipalityCode\")\n\n\nSimple feature collection with 0 features and 10 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n# A tibble: 0 × 11\n# ℹ 11 variables: OBJECTID &lt;int&gt;, ProvinceCode &lt;chr&gt;, ProvinceName &lt;chr&gt;,\n#   LocalMunicipalityCode &lt;chr&gt;, LocalMunicipalityName &lt;chr&gt;,\n#   DistrictMunicipalityCode &lt;chr&gt;, DistrictMunicipalityName &lt;chr&gt;, Year &lt;int&gt;,\n#   Shape__Area &lt;dbl&gt;, Shape__Length &lt;dbl&gt;, geometry &lt;GEOMETRY [°]&gt;\n\n\nCode\nanti_join(education, municipal, by = \"LocalMunicipalityCode\")\n\n\n# A tibble: 0 × 8\n# ℹ 8 variables: LocalMunicipalityCode &lt;chr&gt;, LocalMunicipalityName &lt;chr&gt;,\n#   No_schooling &lt;dbl&gt;, Some_primary &lt;dbl&gt;, Complete_primary &lt;dbl&gt;,\n#   Some_secondary &lt;dbl&gt;, Grade_12_Std_10 &lt;dbl&gt;, Higher &lt;dbl&gt;\n\n\nWe therefore join the data to the map using the variable LocalMunicipalityCode and check that the schooling data are now attached to the map.\n\n\nCode\nmunicipal &lt;- left_join(municipal, education, by = \"LocalMunicipalityCode\")\nnames(municipal)\n\n\n [1] \"OBJECTID\"                 \"ProvinceCode\"            \n [3] \"ProvinceName\"             \"LocalMunicipalityCode\"   \n [5] \"LocalMunicipalityName.x\"  \"DistrictMunicipalityCode\"\n [7] \"DistrictMunicipalityName\" \"Year\"                    \n [9] \"Shape__Area\"              \"Shape__Length\"           \n[11] \"geometry\"                 \"LocalMunicipalityName.y\" \n[13] \"No_schooling\"             \"Some_primary\"            \n[15] \"Complete_primary\"         \"Some_secondary\"          \n[17] \"Grade_12_Std_10\"          \"Higher\"                  \n\n\n\nNote that the variables LocalMunicipalityName.x and LocalMunicipalityName.y have been created in the process of the join. This is because we did not use LocalMunicipalityName for the join but that variable name is present in both the map and the data and is therefore duplicated when they are joined together – municipal$LocalMunicipalityName becomes municipal$LocalMunicipalityName.x and education$LocalMunicipalityName creates municipal$LocalMunicipalityName.y."
  },
  {
    "objectID": "thematicmaps.html#mapping-the-data",
    "href": "thematicmaps.html#mapping-the-data",
    "title": "Thematic maps in R",
    "section": "Mapping the data",
    "text": "Mapping the data\n\nUsing plot{sf}\nThe ‘one line’ way of plotting the data is to use the in-built plot() function for sf.\n\n\nCode\nplot(municipal[\"No_schooling\"])\n\n\n\n\n\nAs a ‘rough and ready’ way to check for spatial variation and patterns in the data, it is quick and easy. It is important to specify the variable(s) you wish to include in the plot or else it will plot them all up to the value specified by the argument max.plot, which has a default of nine.\n\n\nCode\nplot(municipal)\n\n\n\n\n\n The map can be customised. For example,\n\n\nCode\nif(!(\"RColorBrewer\" %in% installed)) install.packages(\"RColorBrewer\",\n                                                      dependencies = TRUE)\nrequire(RColorBrewer)\n\nplot(municipal[\"No_schooling\"], key.pos = 1, breaks = \"jenks\", nbreaks = 7,\n     pal = rev(brewer.pal(7, \"RdYlBu\")),\n     graticule = TRUE, axes = TRUE,\n     main = \"Percentage of Population with No Schooling\")\n\n\n\n\n\nHave a read through the documentation at ?sf::plot to get a sense of what the various arguments do. Try changing them and see if you can produce a map with six equal interval breaks, for example.\nNote the use of the RColorBrewer package and its brewer.pal() function. RColorBrewer provides colour palettes based on https://colorbrewer2.org/ and has been used to create a diverging red-yellow-blue colour palette that is reversed using the function rev() so that red is assigned to the highest values, not lowest. A ‘natural breaks’ (jenks) classification with 7 colours has been used (breaks = \"jenks\", nbreaks = 7).\n\n\nThinking about the map classes\nHere is the same underlying map but with equal interval breaks instead:\n\n\nCode\nplot(municipal[\"No_schooling\"], key.pos = 1, breaks = \"equal\", nbreaks = 7,\n     pal = rev(brewer.pal(7, \"RdYlBu\")),\n     graticule = TRUE, axes = TRUE,\n     main = \"Percentage of Population with No Schooling\")\n\n\n\n\n\n… and here with quantile breaks:\n\n\nCode\nplot(municipal[\"No_schooling\"], key.pos = 1, breaks = \"quantile\", nbreaks = 7,\n     pal = rev(brewer.pal(7, \"RdYlBu\")),\n     graticule = TRUE, axes = TRUE,\n     main = \"% of Population with No Schooling\")\n\n\n\n\n\nClearly the maps above do not appear exactly the same. This because the geographical patterns and therefore the geographical information that we view in the map are a function of how the map is constructed, including the number, colouring and widths (ranges) of the map classes. Ideally, these should be set to reflect the distribution of the data and what is being look for in it.\nThe following histograms show the break points in the distributions used in the various maps. The code works by creating a list of plots (specifically, a list of ggplots, see below) – one plot each for the jenks, equal and quantile styles – and then, using a package called gridExtra, to arrange those plots into a single grid. However, the code matters less than what it reveals, which is that Jenks or other ‘natural breaks’ classifications are reasonably good for identifying break points that reflect the distribution of the data in the absence of the user having cause to set those break points in some other way.\nThinking about the distribution of the data is important to avoid creating maps that give the wrong impression of the prevalence or otherwise of values in the data. For example, if you use a quantile classification with, say, 4 breaks, it will create four map classes, each containing approximately one quarter of the data, even if some of the values in those classes are rarely found and unusual when compared to others in the same class. An equal interval classification will not have this problem.\n\n\nCode\nif(!(\"gridExtra\" %in% installed)) install.packages(\"gridExtra\",\n                                                   dependencies = TRUE)\nif(!(\"classInt\" %in% installed)) install.packages(\"classInt\",\n                                                  dependencies = TRUE)\n\nrequire(gridExtra)\nrequire(classInt)\n\nstyles &lt;- c(\"jenks\", \"equal\", \"quantile\")\ng &lt;- lapply(styles, \\(x) {\n        ggplot(municipal, aes(x = No_schooling)) +\n        geom_histogram(fill = \"light grey\") +\n        xlab(\"% of Population with No Schooling\") +\n        geom_vline(xintercept = classIntervals(municipal$No_schooling,\n                                               n = 7, style = x)$brks,\n                   col = \"dark red\") +\n        geom_rug() +\n        theme_minimal() +\n        ggtitle(paste(x,\"classification\"))\n    })\n# The step below brings together, in a grid, the list of three different plots\n# created above\ngrid.arrange(grobs = g)\n\n\n\n\n\n For further information on using plot{sf} see here and look at the help menu, ?sf::plot."
  },
  {
    "objectID": "thematicmaps.html#using-ggplot2",
    "href": "thematicmaps.html#using-ggplot2",
    "title": "Thematic maps in R",
    "section": "Using ggplot2",
    "text": "Using ggplot2\nWhilst the plot() function for sf objects is useful for producing quick maps, I tend to prefer ggplot2 for better quality ones that I am wanting to customise or annotate in particular ways. We already have seen examples of ggplot2 output in earlier sessions and also in the histograms above.\nggplot2 is based on The Grammar of Graphics. I find it easiest to think of it, initially, in four stages:\n\nSay which data are to be plotted;\nSay which aesthetics of the chart (e.g. colour, line type, point size) will vary with the data;\nSay which types of plots (which ‘geoms’) are to feature in the chart;\n(Optional) change other attributes of the chart to add titles, rename the axis labels, and so forth.\n\nAs an example, in the code chunk below, those four stages are applied to a boxplot showing the distribution of the no schooling variable by South African Provinces.\nFirst, the data = municipal. Second, consulting with the ggplot2 cheatsheet, I find that the aesthetics, aes(), for the boxplot, require a discrete x and a continuous y, which are provided by ProvinceName and No_schooling, respectively. ProvinceName has also been used to assign a fill colour to each box. Third, the optional changes arise from me preferring theme_minimal() to the default style, although I have then modified it to remove the legend, change the angle of the text on the x-axis, remove the x-axis label and change the y-axis label.\n\n\nCode\nggplot(data = municipal, aes(x = ProvinceName, y = No_schooling,\n                             fill = ProvinceName)) +\n  geom_boxplot() +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45)) +\n  xlab(element_blank()) +\n  ylab(\"% No schooling within municipalities\")\n\n\n\n\n\n Let’s now take that process and apply it to create a map, using the same RColorBrewer colour palette as previously and adding the map using geom_sf (for a full list of geoms available for ggplot2 see here). The line scale_fill_distiller is an easy way to shade the map using the colour palette from RColorBrewer andlabs() adds labelling.\n\n\nCode\nggplot(municipal, aes(fill = No_schooling)) +\n  geom_sf() +\n  scale_fill_distiller(\"%\", palette = \"RdYlBu\") +\n  theme_minimal() +\n  labs(\n    title = \"Percentage of Population with No Schooling\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  )  \n\n\n\n\n\n Presently the map has a continuous shading scheme – you can see it in the map’s legend. This can be changed to discrete map classes and colours by converting the continuous municipal$No_schooling variable to a factor, using the cut() function, here with break points found using ClassIntervals(style = \"jenks\"). Because we have then changed from continuous to discrete (categorised) data but still want to use an RColorBrewer palette, so scale_fill_brewer() replaces scale_fill_distiller(), wherein the argument direction = -1 reverses the RdYlBu palette so that the highest values are coloured red. Adding guides(fill = guide_legend(reverse = TRUE)) reverses the legend so that the highest values are on top in the legend, which is another preference of mine.\n\n\nCode\n# Find the break points in the distribution using a Jenks classification\nbrks &lt;- classIntervals(municipal$No_schooling, n = 7, style = \"jenks\")$brks\n\n# Factor the No_schooling variable using those break points\nmunicipal$No_schooling_gp &lt;- cut(municipal$No_schooling, brks,\n                                 include.lowest = TRUE)\n\nggplot(municipal, aes(fill = No_schooling_gp)) +\n  geom_sf() +\n  scale_fill_brewer(\"%\", palette = \"RdYlBu\", direction = -1) +\n  theme_minimal() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Percentage of Population with No Schooling\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  ) \n\n\n\n\n\nAt this point, we may note that the four stages of the map production that I referred to earlier was an over-simplification and we can add a fifth:\n\nSay which data are to be plotted;\nSay which aesthetics of the chart (e.g. colour, line type, point size) will vary with the data;\nSay which types of plots (which ‘geoms’) are to feature in the chart – geom_sf for mapping;\n‘Scale’ the data – in the above examples, link the mapped variables to map classes and colour codes. The scaling is what scale_fill_... was doing;\n(Optional) change other attributes of the chart to add titles, rename the axis labels, and so forth.\n\n\nAnnotating the map with ggspatial\nHaving created the basic map using ggplot2, we can add some additional map elements using ggspatial, which provides some extra cartographic functions. The following code chunk adds a backdrop to the map. Different backgrounds (alternative map tiles) can be chosen from the list at rosm::osm.types(); see here for what they look like.\nBefore running the code, we may note a change from the previous code chunk (above) which is in addition to installing and requiring ggspatial and adding the map tile as a backdrop. Specifically, if you look at the previous code chunk you will find that the data, municipal are handed-to ggplot in the top line ggplot(municipal, ...) where the first argument is the data one. In other words, ggplot(municipal, ...) is the same as, ggplot(data = municipal, ...) (check the help file, ?ggplot2::ggplot to confirm this). By specifying the data in the top line, in essence this sets data = municipal as a global parameter for the plot: it is where ggplot will, by default, now look for the variable called for in aes(fill = No_schooling_gp) and where it will look for other variables too. Whilst this would work just fine in the code immediately below, a little later I introduce a second geom_sf into the plot and no longer want municipal to be the default choice for all the aesthetics of the chart, just some of them. To pre-empt any problems that might otherwise arise, I no longer specify municipal as the default dataset in my ggplot() but, instead, specifically name municipal where I want to use it – as the fill data, in the line geom_sf(data = municipal, aes(fill = No_schooling_gp)) – which will leave me free to associate other data with different aesthetics in due course. More simply, if you set the data = argument and also any aesthetics, mapping = aes() then you are basically saying “use these for everything that follows” unless you override them by saying what you want for each specific geom.\n\n\nCode\nif(!(\"ggspatial\" %in% installed)) install.packages(\"ggspatial\",\n                                                   dependencies = TRUE)\nrequire(ggspatial)\n\nggplot() +\n  annotation_map_tile(type = \"cartolight\", progress = \"none\") +\n  geom_sf(data = municipal, aes(fill = No_schooling_gp)) +\n  scale_fill_brewer(\"%\", palette = \"RdYlBu\", direction = -1) +\n  theme_minimal() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Percentage of Population with No Schooling\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  ) \n\n\n\n\n\n A north arrow and a scale bar can also be added, although including the scale bar generates a warning because the map to true life distance ratio is not actually constant across the map but varies with longitude and latitude. The argument, location = \"tl\" is short for top left; location = \"br\" for bottom right. See ?annotation_north_arrow and ?annotation_scale for further details and options. Note also the use of the last_plot() function to more easily add content to the last ggplot.\n\n\nCode\nlast_plot() +\n  annotation_north_arrow(location = \"tl\",\n                         style = north_arrow_minimal(text_size = 14)) +\n  annotation_scale(location = \"br\", style = \"ticks\")\n\n\n\n\n\n\n\nAdding point symbols to the map\nIn the next example, the locations of South African cities are added to the map, with a symbol drawn in proportion to their population size. The source of the data is a shapefile from https://data.humdata.org/dataset/hotosm_zaf_populated_places. The symbol shape that is specified by pch = 3 has the same numeric coding as those in ?graphics::points (i.e. 0 is a square, 1, is a circle, 2 is a triangle, and so forth).\n\nThe function scales::label_comma() forces decimal display of numbers to avoid displaying scientific notation.\n\nThe notation [pagkage_name]::[function] is a way of saying in which library/package a specific function is found - the label_comma() function is in the scales library. Sometimes this can be useful to run a function from a package/library without first requiring (loading) it. It can also be useful to avoid the problem when two packages contain a function with the same name. For example, there is a select() function in both the ’raster and dplyr libraries. If you require (load) both of these libraries then the select function in whichever is loaded second will mask the select function in the one loaded first, potentially causing errors or confusions. A way around the problem is to use the :: notation to be specific about which package’s select you wish to use, i.e. raster::select() or dplyr::select().\n\n\nCode\nif(!(\"scales\" %in% installed)) install.packages(\"scales\", dependencies = TRUE)\n\ndownload.file(\"https://github.com/profrichharris/profrichharris.github.io/blob/main/MandM/boundary%20files/hotosm_zaf_populated_places_points_shp.zip?raw=true\",\n              \"cities.zip\", mode = \"wb\", quiet = TRUE)\nunzip(\"cities.zip\")\n\nread_sf(\"hotosm_zaf_populated_places_points.shp\") |&gt;\n  filter(place == \"city\") |&gt;\n  mutate(population = as.numeric(population)) -&gt;\n  cities\n\nlast_plot() +\n  geom_sf(data = cities, aes(size = population), pch = 3) +\n  scale_size(\"Population\", labels = scales::label_comma())\n\n\n\n\n\n\nSlightly confusingly, a shapefile actually consists of at least three files, one with the extension .shp (the coordinate/shape data), one .shx (an index file) and one .dbf (the attribute data). If you use a shapefile you need to make sure you download all of them and keep them together in the same folder.\n\n\nLabelling using ggsflabel\nNice labelling of the cities is provided by ggsflabel, in this example using a pipe |&gt; to filter and only label cities with over a million population. The function geom_sf_label_repel() is designed to stop labels from being placed over each other. We could use last_plot() again to create this map but, instead, here is the code in full:\n\n\nCode\nif(!(\"remotes\" %in% installed)) install.packages(\"remotes\", dependencies = TRUE)\nif(!(\"ggsflabel\" %in% installed)) remotes::install_github(\"yutannihilation/ggsflabel\")\nrequire(ggsflabel)\n\nggplot() +\n  annotation_map_tile(type = \"cartolight\", progress = \"none\") +\n  geom_sf(data = municipal, aes(fill = No_schooling_gp)) +\n  scale_fill_brewer(\"%\", palette = \"RdYlBu\", direction = -1) +\n    geom_sf(data = cities, aes(size = population), pch = 3) +\n  scale_size(\"Population\", labels = scales::label_comma()) +\n  geom_sf_label_repel(data = cities |&gt; filter(population &gt; 1e6),\n                    aes(label = name), alpha = 0.7, size = 3) +\n  theme_minimal() +\n  # The line below removes some annoying axis titles that otherwise appear\n  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Percentage of Population with No Schooling\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  ) \n\n\n\n\n\n\n\nSaving the map as a graphic file\nHaving created the map, it can now be saved as a graphic. If you are not using an R Project to save your files into, you may wish to change your working directory before saving the graphic, using setwd(dir) and substituting dir with the pathname to the preferred directory, or by using Session -&gt; Set Working Directory -&gt; Choose Directory from the dropdown menus. Once you have done so, the last_plot() is easily saved using the function ggsave(). For example, in .pdf format, to a print quality,\n\n\nCode\nggsave(\"no_schooling.pdf\", device = \"pdf\", width = 6, units = \"in\",\n       dpi = \"print\")\n\n\nAlternatively, we can write directly to a graphics device, using one of the functions bmp(), jpeg(), png(), tiff() or pdf(). For instance,\n\n\nCode\njpeg(\"no_schooling.jpg\", res = 72)\nlast_plot()\ndev.off()"
  },
  {
    "objectID": "thematicmaps.html#creating-an-interactive-map-using-ggiraph",
    "href": "thematicmaps.html#creating-an-interactive-map-using-ggiraph",
    "title": "Thematic maps in R",
    "section": "Creating an interactive map using ggiraph",
    "text": "Creating an interactive map using ggiraph\nSo far all the maps we have created have been static. This is obviously better for anything that will be printed but, for a website or similar, we may wish to include more ‘interaction’. The package ggiraph package creates dynamic ggplot2 graphs and we can use it to create an interactive map where information about the areas appears as we brush over those areas on the map with the mouse pointer. This is achieved by replacing, in the code, geom_sf() with the geom_sf_interactive() function from ggiraph, specifying the text to show with the tooltip (the example below pastes a number of character elements together without a space between them, hence paste0() but does include a carriage return, \\n) and rendering the resulting ggplot2 object with girafe().\n\n\nCode\nif(!(\"ggiraph\" %in% installed)) install.packages(\"ggiraph\", dependencies = TRUE)\nrequire(ggiraph)\n\ng &lt;- ggplot() +\n  annotation_map_tile(type = \"cartolight\", progress = \"none\") +\n  geom_sf_interactive(data = municipal,\n                      aes(tooltip = paste0(LocalMunicipalityName.x, \"\\n\",\n                                           round(No_schooling,1), \"%\"),\n                             fill = No_schooling_gp)) +\n  scale_fill_brewer(\"%\", palette = \"RdYlBu\", direction = -1) +\n  theme_minimal() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Percentage of Population with No Schooling\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  ) +\n  annotation_north_arrow(location = \"tl\",\n                         style = north_arrow_minimal(text_size = 14)) +\n  annotation_scale(location = \"br\", style = \"ticks\")\n\ngirafe(ggobj = g)\n\n\n\n\n\n\n\nSave your workspace\nThis is the end of Part 1 and may be a good place to stop or, at least, take a break. If you won’t be continuing immediately to Part 2 then don’t forget to save your workspace. For example, by using,\n\n\nCode\nsave.image(\"making_maps.RData\")"
  },
  {
    "objectID": "thematicmaps.html#bivarite-mapping-with-ggplot2",
    "href": "thematicmaps.html#bivarite-mapping-with-ggplot2",
    "title": "Thematic maps in R",
    "section": "Bivarite Mapping with ggplot2",
    "text": "Bivarite Mapping with ggplot2\nSometimes we want to the colours on the map to reflect the combination of two variables’ values, not just one. We used to be able to use the bivariate package to do this. Unfortunately, this does not appear to be available any more and whilst it is possible to download achieved versions, the most recent was not working for me and could create conflicts with newer packages. We can, however, undertake the process ‘by hand’.\nTo illustrate, let’s use the two variables, municipal$No_schooling and municipal$Higher. One measures the percentage of the population without schooling per South African municipality in 2011 and we shall use it to create a new variable, the percentage with schooling; the other is the percentage with higher education. The following code creates the bivariate map. The process is broadly that described in this tutorial but I have changed and simplified it a little. It may not look especially simple but there is not much to it that we have not done already. The main difference is that we are cutting (categorising) the data along two variables and then creating a colour scheme and a legend to represent the resulting groups.\n\n\nCode\n# First, split the municipalities into three groups (categories) based on the % Schooling\ntertiles_schooling &lt;- municipal |&gt;\n  # Create the new schooling variable from no_schooling:\n  mutate(Schooling = 100 - No_schooling) |&gt;\n  # Take the Schooling variable and cut it into the groups:\n  pull(Schooling) %&gt;%\n  cut(., breaks = quantile(., probs = seq(0, 1, length.out = 4)),\n                           labels = FALSE,\n                           include.lowest = TRUE)\n\n# Second, split the municipalities into three groups based on the % higher education\ntertiles_higher &lt;- municipal |&gt;\n  pull(Higher) %&gt;%\n  cut(., breaks = quantile(., probs = seq(0, 1, length.out = 4)),\n                           labels = FALSE,\n                           include.lowest = TRUE)\n\n# Third, add those groups to the map's attribute data and also combine them\nmunicipal$schooling_gp  &lt;- tertiles_schooling\nmunicipal$higher_gp  &lt;- tertiles_higher\nmunicipal$combined_gp &lt;- paste(tertiles_schooling, tertiles_higher, sep = \" - \")\n\n# Here is what has been created\nmunicipal |&gt; \n  st_drop_geometry() |&gt;\n  select(schooling_gp, higher_gp, combined_gp) |&gt;\n  slice_head(n = 5)\n\n\n# A tibble: 5 × 3\n  schooling_gp higher_gp combined_gp\n         &lt;int&gt;     &lt;int&gt; &lt;chr&gt;      \n1            3         3 3 - 3      \n2            3         3 3 - 3      \n3            2         2 2 - 2      \n4            2         2 2 - 2      \n5            3         3 3 - 3      \n\n\nCode\n# Fourth, define a colour scheme, here using hex colour codes\n# https://www.joshuastevens.net/cartography/make-a-bivariate-choropleth-map/ is helpful\ncols &lt;- c(\n  \"3 - 3\" = \"#e8e8e8\", # highest primary and secondary\n  \"2 - 3\" = \"#cbb8d7\",\n  \"1 - 3\" = \"#9972af\", # lowest primary, highest secondary\n  \"3 - 2\" = \"#e4d9ac\",\n  \"2 - 2\" = \"#c8ada0\", # medium primary, medium secondary\n  \"1 - 2\" = \"#976b82\",\n  \"3 - 1\" = \"#c8b35a\", # highest primary, lowest secondary\n  \"2 - 1\" = \"#8f8e53\",\n  \"1 - 1\" = \"#804d36\" # low primary, lowest secondary\n)\n\n# Now create the map, omitting the legend\nmap &lt;- ggplot() +\n  geom_sf(data = municipal, aes(fill = combined_gp)) +\n  scale_fill_manual(values = cols, guide = FALSE) +\n  geom_sf(data = cities, pch = 21, bg = \"light grey\") +\n  geom_sf_label_repel(data = cities |&gt; filter(population &gt; 0.25e6),\n                    aes(label = name), alpha = 0.7, size = 3) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +\n  labs(\n    title = \"Levels of education in South African municipalities\",\n    subtitle = \"2011 South African Census Data\",\n    caption = \"Source: Statistics South Africa\"\n  ) +\n  annotation_north_arrow(location = \"tl\",\n                         style = north_arrow_minimal(text_size = 14))\n\n# Create the map's legend\n# It should be more obvious what this does once it is plotted\nlegend &lt;- ggplot() +\n  geom_tile(\n    data = municipal,\n    mapping = aes(\n      x = schooling_gp,\n      y = higher_gp,\n      fill = combined_gp)) +\n  scale_fill_manual(values = cols, guide = FALSE) +\n  labs(x = \"← ← Lower % Schooling\",\n       y = \"← ← Lower % HE\") +\n  coord_fixed() +\n  theme(axis.title = element_text(size = 7.5),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        panel.background = element_blank())\n\nif(!(\"cowplot\" %in% installed)) install.packages(\"ggiraph\", dependencies = TRUE)\nrequire(cowplot)\n\n# Use the ggdraw() function in cowplot to combine the map and legend together\nggdraw() +\n  draw_plot(map, 0, 0, 1, 1) +\n  draw_plot(legend, 0.75, 0.1, 0.25, 0.25)"
  },
  {
    "objectID": "thematicmaps.html#using-tmap",
    "href": "thematicmaps.html#using-tmap",
    "title": "Thematic maps in R",
    "section": "Using tmap",
    "text": "Using tmap\nClearly there is a lot of scope to produce high quality maps using ggplot2 and various associated packages. However, it has a rival, in tmap, which is arguably easier to use. Like ggplot2, tmap adopts the Grammar of Graphics but approaches it in a slightly different way that uses layers: it builds-up the layers of the graphic by first specifying a spatial object or background, then doing things to the map based on it, then specifying another spatial object and/or other map elements to do things with, and so forth. The types of layers available can be viewed here and here. A brief introduction to tmap is available here.\nThe code chunk a little further below builds-up the layers of the map to produce one quite like that previously created in ggplot2. First, however, there is a error in the geometry of the underlying municipal map file to deal with:\n\n\nCode\nall(st_is_valid(municipal))\n\n\n[1] FALSE\n\n\nThe problem lies in the 128th area, where one edge crosses another,\n\n\nCode\nst_is_valid(municipal[128,], reason = TRUE)\n\n\n[1] \"Edge 25 crosses edge 27\"\n\n\ntmap is less forgiving of this error than ggplot2 is. A temporary ‘fix’ – more of a side-step really – is achieved by changing the coordinate reference system, which presently is using EPSG: 4326 (you can see this with st_crs(municipal)), to EPSG: 3857.\n\n\nCode\nmunicipal &lt;- st_transform(municipal, 3857)\nall(st_is_valid(municipal))\n\n\n[1] TRUE\n\n\nNow we can produce the plot, to give an output similar to one of the earlier ggplots:\n\n\nCode\nif(!(\"tmap\" %in% installed)) install.packages(\"tmap\", dependencies = TRUE)\nrequire(tmap)\n\ntmap_mode(\"plot\")\n\ntm_graticules(col = \"light grey\") +\n  tm_shape(municipal, is.master = TRUE) +\n  tm_fill(\"No_schooling\", palette = \"-RdYlBu\", title = \"%\", style = \"jenks\",\n          n = 7) +\n  tm_borders(col = \"black\") +\n  tm_shape(cities) +\n  tm_dots(size = \"population\", shape = 3) +\n  tm_shape(cities |&gt; filter(population &gt; 1e6)) + \n  tm_text(\"name\", bg.color = \"white\", auto.placement = TRUE, bg.alpha = 0.6) +\n  tm_legend(title = \"Percentage of Population with No Schooling\",\n            bg.color = \"white\", bg.alpha = 0.7) +\n  tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n  tm_scale_bar(position = c(\"right\", \"bottom\"), bg.color = \"white\") +\n  tm_credits(\"Source: 2011 Census / Statistics South Africa\",\n             bg.color = \"white\")\n\n\n\n\n\n The map looks pretty good and can be saved using the function tmap_save. For example,\n\n\nCode\ntmap_save(tmap_last(), \"no_schooling2.jpg\", width = 7, units = \"in\")\n\n\nHowever, there is a cartographic/mathematical irritation that might bug a reviewer if you were to submit the map as part of an academic journal (or a marker if you were to submit the map for assessment!). If you look at the map classes, they are non-unique: e.g. 5.64 to 9.87, 9.87 to 13.38, 13.38 to 17.19, and so forth. Which category would a value of 9.87 (or 13.38, etc.) fall into?\nTo solve this problem, we can do what we did for the ggplots, which is to create a factor from the municipal$No_schooling variable, which is what the first two lines of code below do. The third line reverses the order of the factors, so that the highest and not lowest valued group is treated as the first level, and so forth. The reason I have added this is because of my preference for the highest values to appear top in the legend.\n\n\nCode\nbrks &lt;- classIntervals(municipal$No_schooling, n = 7, style = \"jenks\")$brks\nmunicipal$No_schooling_gp &lt;- cut(municipal$No_schooling, brks,\n                                 include.lowest = TRUE)\nmunicipal$No_schooling_gp &lt;- factor(municipal$No_schooling_gp,\n                                levels = rev(levels(municipal$No_schooling_gp)))\n\ntm_graticules(col = \"lightgrey\") +\n  tm_shape(municipal) +\n  tm_fill(\"No_schooling_gp\", palette = \"RdYlBu\", title = \"%\") +\n  tm_borders(col = \"black\") +\n  tm_shape(cities) +\n  tm_dots(size = \"population\", shape = 3) +\n  tm_shape(cities %&gt;% filter(population &gt; 1e6)) + \n  tm_text(\"name\", bg.color = \"white\", auto.placement = TRUE, bg.alpha = 0.6) +\n  tm_legend(title = \"Percentage of Population with No Schooling\",\n            bg.color = \"white\", bg.alpha = 0.7) +\n  tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n  tm_scale_bar(position = c(\"right\", \"bottom\"), bg.color = \"white\") +\n  tm_credits(\"Source: 2011 Census / Statistics South Africa\",\n             bg.color = \"white\")\n\n\n\n\n\n Where tmap really excels is in rendering interactive maps to leaflet by changing the tmap_mode from tmap_mode(\"plot\")to tmap_mode(\"view\"). The following allows panning and can be zoomed in and out of. Unfortunately, it also reveals that the earlier ‘fix’ to the municipal object doesn’t work here so I have omitted the problem area, although that isn’t much of a solution.\n\n\nCode\ntmap_mode(\"view\")\n\ntm_basemap(\"Stamen.Watercolor\") +\n  tm_shape(municipal[-128,], name = \"municipalities\") +\n  tm_fill(\"No_schooling_gp\", palette = \"RdYlBu\", title = \"%\") +\n  tm_borders(col = \"black\") +\n  tm_shape(cities) +\n  tm_dots(size = \"population\") +\n  tm_legend(title = \"Percentage of Population with No Schooling\",\n            bg.color = \"white\", bg.alpha = 0.7) +\n  tm_scale_bar(position = c(\"right\", \"bottom\"), bg.color = \"white\")\n\n\n\n\n\n\n\nThe following version adds further functionality. It allows different map layers to be displayed (move your mouse cursor over the map layers icon to do so) and, if you right click on any of the areas shown, will bring-up information about them.\n\n\nCode\ntm_basemap(c(Stamen = \"Stamen.Watercolor\",\n             Carto = \"CartoDB\",\n             OSM = \"OpenStreetMap\")) +\n  tm_shape(municipal[-128,], name = \"municipalities\") +\n  tm_fill(\"No_schooling_gp\", palette = \"RdYlBu\", title = \"%\",\n          id = \"LocalMunicipalityName.x\",\n          popup.vars = c(\"% No schooling:\" = \"No_schooling\",\n                         \"Province: \" = \"ProvinceName\"),\n          popup.format = list(digits = 1)) +\n  tm_borders(col = \"black\") +\n  tm_shape(cities) +\n  tm_dots(size = \"population\",\n          id = \"name\",\n          popup.vars = c(\"Population: \" = \"population\")) +\n  tm_legend(title = \"Percentage of Population with No Schooling\",\n            bg.color = \"white\", bg.alpha = 0.7) +\n  tm_scale_bar(position = c(\"right\", \"bottom\"), bg.color = \"white\") +\n  tm_view(view.legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n \nDifferent layers are available dependent upon the tmap_mode. For example, there is no straightforward way of adding a maptile (tm_basemap) as the backdrop to a map in tmap’s \"plot\" mode, or a compass (tm_compass) or a scale bar (tm_scale_bar) in \"view\" mode.\n We can also have some fun! Here is an animated map where the animation is produced from a combination of the tm_facets(along = \"ProvinceName\", free.coords = FALSE) layer and the use of the tmap_animation() function. Notice how I add municipal to the map twice, as two separate layers. The first is to provide a general backdrop to the map with all the municipalities shaded grey. They second is linked to the animation with the municipalities shaded by the percentage of their population without schooling.\n\n\nCode\nif(!(\"gifski\" %in% installed)) install.packages(\"gifski\", dependencies = TRUE)\n\ntmap_mode(\"plot\")\n\nt &lt;- tm_graticules(col = \"light grey\") +\n  tm_shape(municipal) +\n  tm_polygons(col = \"grey\", border.col = \"black\") +\n  tm_shape(municipal) +\n  tm_fill(\"No_schooling_gp\", palette = \"RdYlBu\", title = \"%\") +\n  tm_borders(col = \"white\") +\n  tm_facets(along = \"ProvinceName\", free.coords = FALSE) +\n  tm_legend(title = \"Percentage of Population with No Schooling\",\n            bg.color = \"white\", bg.alpha = 0.7) +\n  tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n  tm_scale_bar(position = c(\"right\", \"bottom\"), bg.color = \"white\") +\n  tm_credits(\"Source: 2011 Census / Statistics South Africa\",\n             bg.color = \"white\")\n\ntmap_animation(t, delay = 100)\n\n\n  \nThe animation may be saved as a .gif file by including the argument filename (see ?tmap_animation).\n Faceting can also be used on static maps, as in the following example, where tm_facets(by = \"ProvinceName\", free.coords = TRUE) creates a choropleth map for each Province, with a common legend, positioned outside each provincial map through the use of tm_layout(legend.outside.position = \"bottom\").\n\n\nCode\ntmap_mode(\"plot\")\n\ntm_graticules(col = \"light grey\") +\n  tm_shape(municipal) +\n  tm_fill(\"No_schooling_gp\", palette = \"RdYlBu\",\n          title = \"% Population with No Schooling\",\n          legend.is.portrait = FALSE) +\n  tm_borders(col = \"white\") +\n  tm_facets(by = \"ProvinceName\", free.coords = TRUE) +\n  tm_compass(type = \"arrow\", position = c(\"right\", \"top\")) +\n  tm_scale_bar(position = c(\"right\", \"bottom\")) +\n  tm_layout(legend.outside.position = \"bottom\")"
  },
  {
    "objectID": "thematicmaps.html#geofacets",
    "href": "thematicmaps.html#geofacets",
    "title": "Thematic maps in R",
    "section": "Geofacets",
    "text": "Geofacets\nTo this point of the session we have been using maps to represent the spatial distribution of one or more variables whose values are plotted as an aesthetic of the map such as colour or shape size. A different approach is offered by the geofacet package which uses geography as a ‘placeholder’ to position graphical summaries of data for different parts of the map. The idea is to flexibly visualise data for different geographical regions by providing a ggplot2 faceting function facet_geo() that works just like ggplot2’s built-in faceting, except that the resulting arrangement of panels follows a grid that mimics the original geographic topology as closely as possible.\nHere is an example of it in use, showing the distribution of municipalities within South African provinces in terms of the percentage of the population with higher education (university) qualifications.\n\n\nCode\nif(!(\"geofacet\" %in% installed)) install.packages(\"geofacet\")\nrequire(geofacet)\n\n# Define a grid that mimics the geographical distribution of the provinces\nmygrid &lt;- data.frame(\n  code = c(\"LIM\", \"GT\", \"NW\", \"MP\", \"NC\", \"FS\", \"KZN\", \"EC\", \"WC\"),\n  name = c(\"Limpopo\", \"Gauteng\", \"North West\", \"Mpumalanga\", \"Northern Cape\",\n           \"Free State\", \"KwaZulu-Natal\", \"Eastern Cape\", \"Western Cape\"),\n  row = c(1, 2, 2, 2, 3, 3, 3, 4, 4),\n  col = c(3, 3, 2, 4, 1, 2, 3, 2, 1),\n  stringsAsFactors = FALSE\n)\n\n# Plot the data with the geofaceting\nggplot(municipal, aes(Higher)) +\n  geom_boxplot(col = \"dark grey\") +\n  geom_density() +\n  geom_rug() +\n  facet_geo(~ ProvinceName, grid = mygrid) +\n  scale_y_continuous(breaks = c(0, 0.2, 0.4)) +\n  theme_bw() +\n  labs(\n    title = \"Percentage of Population with higher education\",\n    caption = \"Source: 2011 Census / Statistics South Africa\"\n  ) +\n  xlab(\"% per municipality\")"
  },
  {
    "objectID": "thematicmaps.html#saving-the-map-and-attribute-data",
    "href": "thematicmaps.html#saving-the-map-and-attribute-data",
    "title": "Thematic maps in R",
    "section": "Saving the map and attribute data",
    "text": "Saving the map and attribute data\nThat’s almost it for now! However, before finishing, we will save the map with the joined attribute data to the working directory as an R object.\n\n\nCode\nsave(municipal, file = \"municipal.RData\")"
  },
  {
    "objectID": "thematicmaps.html#summary",
    "href": "thematicmaps.html#summary",
    "title": "Thematic maps in R",
    "section": "Summary",
    "text": "Summary\nThis session has demonstrated that R is a powerful tool for drawing publication quality maps. The native plot functions for sf objects are useful as a quick way to draw a map and both ggplot2 and tmap offer a range of functionality to customise their cartographic outputs to produce really nice looking maps. I tend to use ggplot2 but that is really more out of habit than anything else as tmap might actually be the easier to use. It depends a bit on whether I am drawing static maps (usually in ggplot2) or interactive ones (probably better in tmap). There are other packages available, too, including mapview, which the following code chunk uses (see also, here), and Leaflet to R. Perhaps the key take-home point is that these maps can look at lot better than those produced by some conventional GIS and have the advantage that they can be linked to other analytically processes in R, as future sessions will demonstrate.\n\n\nCode\nif(!(\"mapview\" %in% installed)) install.packages(\"mapview\", dependencies = TRUE)\nrequire(mapview)\n\nmapview(municipal %&gt;% mutate(No_schooling = round(No_schooling, 1)), \n        zcol = \"No_schooling\",\n        layer.name = \"% No Schooling\",\n        map.types = \"Stamen.Watercolor\",\n        col.regions = colorRampPalette(rev(brewer.pal(9, \"RdYlBu\"))))"
  },
  {
    "objectID": "thematicmaps.html#further-reading",
    "href": "thematicmaps.html#further-reading",
    "title": "Thematic maps in R",
    "section": "Further reading",
    "text": "Further reading\n\nChapter 2 on Spatial data and R packages for mapping from Geospatial Health Data by Paula Morga.\n\nChapter 9 on Making maps with R from Geocomputation with R by Robin Lovelace, Jakub Nawosad & Jannes Muenchow.\n\nChapter 8 on Plotting spatial data from Spatial Data Science with Applications in R by Edzer Pebesma and Roger Bivand.\nSee also: Elegant and informative maps with tmap, which is a work in progress by Martijn Tennekes and Jakub Nowosad."
  },
  {
    "objectID": "thematicmaps.html#maps-in-shiny",
    "href": "thematicmaps.html#maps-in-shiny",
    "title": "Thematic maps in R",
    "section": "Maps in Shiny",
    "text": "Maps in Shiny\nShiny is described as “an open source R package that provides an elegant and powerful web framework for building web applications using R” [or Python]. At the time of writing, there is a nice example of a mapping application on the Shiny homepage.\nTeaching Shiny in detail is beyond the scope of this course but there are Getting Started guides (for both R and Python) and a gallery of applications which can be viewed here.\nThe following code creates an app that allows variables from the South African municipality data to be selected and mapped, with various choices for the maps classes and colour palette. Don’t worry if not all of the code makes sense to you but hopefully you will recognise some parts from this session and will see that the basis of the app is to define a user interface and then to define tasks on the server side that will take some inputs from selections made by the user in the interface.\n\n\nCode\n# This checks that the required packages are installed and then loaded\ninstalled &lt;- installed.packages()[,1]\npkgs &lt;- c(\"shiny\", \"sf\", \"dplyr\", \"ggplot2\", \"sf\", \"classInt\", \"RColorBrewer\",\n          \"ggspatial\")\ninstall &lt;- pkgs[!(pkgs %in% installed)]\nif(length(install)) install.packages(install, dependencies = TRUE)\ninvisible(lapply(pkgs, require, character.only = TRUE))\n\n# This downloads the map and the data and merges them\nmap &lt;- read_sf(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/boundary%20files/MDB_Local_Municipal_Boundary_2011.geojson\")\nmapping_data &lt;- read_csv(\"https://github.com/profrichharris/profrichharris.github.io/raw/main/MandM/data/education.csv\")\nmap &lt;- left_join(map, mapping_data, by = \"LocalMunicipalityCode\")\n\n# This selects out from the data the variables of interest\ndf &lt;- map |&gt;\n  st_drop_geometry() |&gt;\n  select(where(is.double), -starts_with(\"Shape\"))\n\n# This defines the user interface\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Educational geographies for South African municipalities\"),\n\n    # Sidebar with various types of input\n    sidebarLayout(\n        sidebarPanel(\n            varSelectInput(\"var\", \"Mapping variable\", df),\n            sliderInput(\"brks\", \"Classes\", min = 3, max = 8, value = 5, step = 1),\n            selectInput(\"type\", \"Classification\", c(\"equal\", \"quantile\", \"jenks\")),\n            selectInput(\"pal\", \"Palette\", rownames(brewer.pal.info)),\n            checkboxInput(\"rev\", \"Reverse palette\"),\n            checkboxInput(\"north\", \"North arrow\")\n          ),\n\n        # The main panel with contain the map plot\n        mainPanel(\n          plotOutput(\"map\")\n        )\n    )\n)\n\n# This defines the server side of the app, taking various inputs\n# from the user interface\nserver &lt;- function(input, output, session) {\n  \n  output$map &lt;- renderPlot({\n    \n    vals &lt;- map |&gt;\n      pull(!!input$var)\n    \n    brks &lt;- classIntervals(vals, n = input$brks, style = input$type)$brks\n    map$gp &lt;- cut(vals, brks, include.lowest = TRUE)\n    \n    \n    p &lt;- ggplot(map, aes(fill = gp)) +\n      geom_sf() +\n      scale_fill_brewer(\"%\", palette = input$pal, direction = ifelse(input$rev, 1, -1)) +\n      theme_minimal() +\n      guides(fill = guide_legend(reverse = TRUE)) +\n      labs(caption = \"Source: 2011 Census, Statistics South Africa\")\n    \n    if(input$north) p &lt;- p + annotation_north_arrow(location = \"tl\",\n                                              style = north_arrow_minimal(text_size = 14))\n  \n    p\n  \n  }, res = 100)}\n\n# This loads and runs the app\nshinyApp(ui, server)\n\n\nYou can play with this app to see how changing the design of the map can easily affect your interpretation of the geography of what it shows. The classic book about this is Mark Monmonier’s How to Lie with Maps."
  }
]